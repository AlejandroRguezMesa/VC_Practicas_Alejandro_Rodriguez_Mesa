{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Trabajo Final, Alejandro Rodríguez Mesa. Autenticación por Reconomiento Facial*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamientos de Modelos YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento para detección de gafas y máscaras o mascarillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "data_Yaml_path = \"C:\\\\Users\\\\aleja\\\\OneDrive\\\\Documentos\\\\VC_Practicas_Alejandro_Rodriguez_Mesa\\\\glasses_and_mask\\\\data.yaml\"\n",
    "\n",
    "results = model.train(data= data_Yaml_path, epochs=40, imgsz=640, batch=16, lr0=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import logging\n",
    "\n",
    "# Configurar logging para reducir los outputs\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Cargar el modelo YOLO entrenado\n",
    "yolo_model = YOLO(r\"runs\\detect\\train6\\weights\\best.pt\")\n",
    "\n",
    "# Mapeo de nombres de clases a sus índices\n",
    "class_names = yolo_model.names\n",
    "\n",
    "# Crear un conjunto de clases que queremos mostrar\n",
    "classes_to_show = {'glasses', 'mask'}\n",
    "# Obtener los índices de las clases que queremos mostrar\n",
    "classes_indices = [index for index, name in class_names.items() if name in classes_to_show]\n",
    "\n",
    "# Inicializar MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Inicializar la captura de video de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se pudo abrir la cámara.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el frame de la cámara.\")\n",
    "        break\n",
    "\n",
    "    # Convertir la imagen a RGB para MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detectar caras con MediaPipe\n",
    "    results = face_detection.process(rgb_frame)\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            # Extraer el bounding box de la cara\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x1, y1, w, h = (int(bboxC.xmin * iw), int(bboxC.ymin * ih),\n",
    "                            int(bboxC.width * iw), int(bboxC.height * ih))\n",
    "            x2, y2 = x1 + w, y1 + h\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Azul para la detección de caras\n",
    "            # Ajustar las coordenadas para mantenerlas dentro de los límites del frame\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(frame.shape[1], x2)\n",
    "            y2 = min(frame.shape[0], y2)\n",
    "\n",
    "            # Recortar la región de la cara\n",
    "            if x2 > x1 and y2 > y1:  # Asegurarse de que las dimensiones sean válidas\n",
    "                face_roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "                if face_roi.size > 0:  # Verificar que el ROI no esté vacío\n",
    "                    # Procesar la región de la cara con YOLO\n",
    "                    yolo_results = yolo_model.predict(face_roi, imgsz=640, conf=0.3)\n",
    "\n",
    "                    # Dibujar detecciones de YOLO en la región de la cara\n",
    "                    for result in yolo_results:\n",
    "                        boxes = result.boxes\n",
    "                        for box in boxes:\n",
    "                            cls_id = int(box.cls)\n",
    "                            if cls_id in classes_indices:\n",
    "                                fx1, fy1, fx2, fy2 = map(int, box.xyxy[0])\n",
    "                                confidence = box.conf[0]\n",
    "                                class_name = class_names[cls_id]\n",
    "\n",
    "                                # Ajustar las coordenadas a la posición en el frame original\n",
    "                                fx1 += x1\n",
    "                                fy1 += y1\n",
    "                                fx2 += x1\n",
    "                                fy2 += y1\n",
    "\n",
    "                                # Dibujar la bounding box y el texto\n",
    "                                color = (0, 255, 0)  # Verde\n",
    "                                cv2.rectangle(frame, (fx1, fy1), (fx2, fy2), color, 2)\n",
    "                                label = f\"{class_name} {confidence:.2f}\"\n",
    "                                (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                                cv2.rectangle(frame, (fx1, fy1 - 20), (fx1 + w, fy1), color, -1)\n",
    "                                cv2.putText(frame, label, (fx1, fy1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "    # Mostrar el frame con las detecciones\n",
    "    cv2.imshow('Detecciones YOLO', frame)\n",
    "\n",
    "    # Salir del loop si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento modelo de detección de Ataques de Presentacion\n",
    "\n",
    "Se detectan imágenes, máscaras y dispositivos que pueden ser usados en spoofing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ultralytics import YOLO\n",
    "#model2 = YOLO('yolo11n.pt') #Contenedores\n",
    "#model2_Yaml_path = \"C:\\\\Users\\\\aleja\\\\OneDrive\\\\Documentos\\\\VC_Practicas_Alejandro_Rodriguez_Mesa\\\\spoofing\\\\data.yaml\"\n",
    "\n",
    "#results_model2 = model2.train(data= model2_Yaml_path, epochs=40, imgsz=640, batch=16, lr0=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Cargar el modelo YOLO entrenado\n",
    "yolo_model2 = YOLO(r\"runs\\detect\\train5\\weights\\best.pt\")\n",
    "# Mapeo de nombres de clases a sus índices\n",
    "# Asegúrate de que estos índices coincidan con los de tu modelo\n",
    "# Si no estás seguro, puedes imprimir model.names para verificar\n",
    "\n",
    "class_names = yolo_model2.names\n",
    "print(class_names)\n",
    "# Crear un conjunto de clases que queremos mostrar\n",
    "classes_to_show = {'Device', 'Masks', 'Photo'}\n",
    "# Obtener los índices de las clases que queremos mostrar\n",
    "classes_indices = [index for index, name in class_names.items() if name in classes_to_show]\n",
    "\n",
    "# Inicializar la captura de video de la cámara (0 es generalmente la cámara predeterminada)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se pudo abrir la cámara.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Presiona 'q' para salir.\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el frame de la cámara.\")\n",
    "        break\n",
    "\n",
    "    # Ejecutar la detección con el modelo\n",
    "    results = yolo_model2.predict(frame, imgsz=640, conf=0.25)\n",
    "\n",
    "    # Procesar los resultados\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Bounding boxes\n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls)  # ID de la clase\n",
    "            if cls_id in classes_indices:\n",
    "                # Obtener coordenadas de la bounding box\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                confidence = box.conf[0]\n",
    "                class_name = class_names[cls_id]\n",
    "\n",
    "                # Dibujar la bounding box\n",
    "                color = (0, 255, 0)  # Verde para las cajas\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                # Preparar el texto con el nombre de la clase y la confianza\n",
    "                label = f\"Spoofing - {class_name} {confidence:.2f}\"\n",
    "\n",
    "                # Obtener el tamaño del texto para un mejor posicionamiento\n",
    "                (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                cv2.rectangle(frame, (x1, y1 - 20), (x1 + w, y1), color, -1)  # Fondo del texto\n",
    "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "    # Mostrar el frame con las detecciones\n",
    "    cv2.imshow('Detecciones YOLO', frame)\n",
    "\n",
    "    # Salir del loop si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas con detector facial Dlib\n",
    "\n",
    "Al inicio tenía claro usar medaipipe, debido a la facilidad de uso, y la extensa malla de puntos que ofrece. Pero al ver que no habian buenos datasets anotados acerca de oclusión en caras, valoré el uso de detectores que sean más sensibles a oclusión. Dlib por ejemplo, tiende a no detectar caras cuando puntos clave como ojos o nariz están ocultos, mientras MediaPipe es menos sensible. Finalmente decidí usar MediaPipe, porque no compensaba la pequeña mejora en descartes ante oclusión a la vez que se perjudica el conteo de pestañeos, la precisión en la estimación de la posición de la cabeza, etcétera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Configurar logging para reducir los outputs\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "\n",
    "# Cargar el modelo YOLO entrenado\n",
    "yolo_model = YOLO(r\"runs\\detect\\train6\\weights\\best.pt\")\n",
    "\n",
    "# Mapeo de nombres de clases a sus índices\n",
    "class_names = yolo_model.names\n",
    "\n",
    "# Crear un conjunto de clases que queremos mostrar\n",
    "classes_to_show = {'glasses'}\n",
    "# Obtener los índices de las clases que queremos mostrar\n",
    "classes_indices = [index for index, name in class_names.items() if name in classes_to_show]\n",
    "\n",
    "# Inicializar Dlib para detección facial y predicción de forma facial\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Función para calcular el aspecto de relación ocular (EAR)\n",
    "def calculate_ear(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Función para dibujar puntos de landmarks\n",
    "def draw_landmarks(canvas, landmarks):\n",
    "    for (x, y) in landmarks:\n",
    "        cv2.circle(canvas, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "# Índices de los puntos de los ojos según el modelo de Dlib\n",
    "LEFT_EYE = list(range(36, 42))\n",
    "RIGHT_EYE = list(range(42, 48))\n",
    "\n",
    "# Parámetros para detectar pestañeos\n",
    "EAR_THRESHOLD = 0.25\n",
    "CONSEC_FRAMES = 3\n",
    "blink_count = 0\n",
    "frame_counter = 0\n",
    "prev_eye_state = \"open\"\n",
    "eye_transition_flag = False\n",
    "\n",
    "def extract_eye_coordinates(shape, eye_indices):\n",
    "    return np.array([(shape.part(i).x, shape.part(i).y) for i in eye_indices], dtype=\"int\")\n",
    "\n",
    "def extract_landmarks(shape):\n",
    "    return np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)], dtype=\"int\")\n",
    "\n",
    "# Inicializar la captura de video de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se pudo abrir la cámara.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el frame de la cámara.\")\n",
    "        break\n",
    "\n",
    "    # Convertir la imagen a escala de grises para Dlib\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar caras con Dlib\n",
    "    faces = face_detector(gray_frame)\n",
    "\n",
    "    for face in faces:\n",
    "        # Obtener las coordenadas del bounding box de la cara\n",
    "        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "\n",
    "        # Ajustar las coordenadas para mantenerlas dentro de los límites del frame\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(frame.shape[1], x2)\n",
    "        y2 = min(frame.shape[0], y2)\n",
    "\n",
    "        # Dibujar la bounding box de la cara en el frame original\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Azul para la detección de caras\n",
    "\n",
    "        # Predecir los puntos clave faciales\n",
    "        shape = shape_predictor(gray_frame, face)\n",
    "\n",
    "        # Extraer las coordenadas de los ojos\n",
    "        left_eye = extract_eye_coordinates(shape, LEFT_EYE)\n",
    "        right_eye = extract_eye_coordinates(shape, RIGHT_EYE)\n",
    "        landmarks = extract_landmarks(shape)\n",
    "\n",
    "        # Dibujar landmarks en la cara\n",
    "        draw_landmarks(frame, landmarks)\n",
    "\n",
    "        # Calcular el EAR para ambos ojos\n",
    "        left_ear = calculate_ear(left_eye)\n",
    "        right_ear = calculate_ear(right_eye)\n",
    "        ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        # Dibujar los ojos en el frame\n",
    "        cv2.polylines(frame, [left_eye], True, (0, 255, 255), 1)\n",
    "        cv2.polylines(frame, [right_eye], True, (0, 255, 255), 1)\n",
    "\n",
    "        # Determinar el estado del ojo y contar pestañeos\n",
    "        eyes_open_now = ear >= EAR_THRESHOLD\n",
    "\n",
    "        if eyes_open_now:\n",
    "            if prev_eye_state == \"closed\" and not eye_transition_flag:\n",
    "                blink_count += 1\n",
    "                eye_transition_flag = True\n",
    "            prev_eye_state = \"open\"\n",
    "        else:\n",
    "            if prev_eye_state == \"open\":\n",
    "                eye_transition_flag = False\n",
    "            prev_eye_state = \"closed\"\n",
    "\n",
    "    # Mostrar el conteo de pestañeos\n",
    "    cv2.putText(frame, f\"Pestaneos: {blink_count}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar el frame con las detecciones\n",
    "    cv2.imshow('Detecciones YOLO', frame)\n",
    "\n",
    "    # Salir del loop si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante - Comprobación de funcionamiento del análisis de imagenes de Deepface\n",
    "Es necesario ejecutar previamente este código para asegurar que funciona el analyze. Puede ser necesario que se descarguen ciertas dependencias de la función. Si falla, se recomienda reiniciar el enviroment y volver a ejecutarlo. Una vez hecho eso, debería de funcionar. Si al clickar en el botón de \"predicciones\" en el login da error, se debe a que las dependencias no se han cargado correctamente, con lo que se debe ejecutar esto, y una vez que funcione, ya se podrá utilizar la funcionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aleja\\anaconda3\\envs\\VC_P4\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age:  21\n",
      "Gender:  {'Woman': 0.06050013471394777, 'Man': 99.93950128555298}\n",
      "Emotion:  neutral\n",
      "Race:  latino hispanic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "# Analyze the image\n",
    "demography = DeepFace.analyze(\"./usuarios/ale/foto_1.png\")\n",
    "\n",
    "# Access the first face's result\n",
    "if isinstance(demography, list):  # If multiple faces are detected\n",
    "    demography = demography[0]\n",
    "\n",
    "print(\"Age: \", demography[\"age\"])\n",
    "print(\"Gender: \", demography[\"gender\"])\n",
    "print(\"Emotion: \", demography[\"dominant_emotion\"])\n",
    "print(\"Race: \", demography[\"dominant_race\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación de la posición de la cabeza con MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Inicializamos MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"No se pudo obtener la imagen de la cámara.\")\n",
    "        break\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Convertimos la imagen a RGB y la volteamos horizontalmente\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Volvemos a BGR para dibujar y mostrar\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, _ = image.shape\n",
    "\n",
    "    # Listas para almacenar coordenadas 2D y 3D de puntos clave\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Recorremos cada landmark y seleccionamos los índices de interés\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                # Usamos varios puntos clave de la cara\n",
    "                if idx in [33, 263, 1, 61, 291, 199]:\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                    \n",
    "                    # Guardamos coordenadas 2D\n",
    "                    face_2d.append([x, y])\n",
    "                    # Guardamos coordenadas 3D (notar que lm.z es relativo)\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "                    # Para proyectar la dirección de la nariz\n",
    "                    if idx == 1:  \n",
    "                        nose_2d = (x, y)\n",
    "                        nose_3d = (x, y, lm.z * 3000)\n",
    "\n",
    "            # Convertimos las listas a arrays de NumPy\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            # Matriz de cámara (focal_length ~ ancho de la imagen)\n",
    "            focal_length = 1 * img_w\n",
    "            cam_matrix = np.array([\n",
    "                [focal_length, 0, img_h / 2],\n",
    "                [0, focal_length, img_w / 2],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "\n",
    "            # Sin distorsión\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            # Resolver PnP\n",
    "            success_pnp, rot_vec, trans_vec = cv2.solvePnP(\n",
    "                face_3d, face_2d, cam_matrix, dist_matrix\n",
    "            )\n",
    "\n",
    "            # Convertir a matriz de rotación\n",
    "            rmat, _ = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "            # Obtener ángulos de rotación\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            x_angle = angles[0] * 360\n",
    "            y_angle = angles[1] * 360\n",
    "            z_angle = angles[2] * 360\n",
    "\n",
    "            # Definir texto según la inclinación de la cabeza\n",
    "            if y_angle < -4:\n",
    "                text = \"Mirando Izq.\"\n",
    "            elif y_angle > 5:\n",
    "                text = \"Mirando Der.\"\n",
    "            elif x_angle < -3:\n",
    "                text = \"Mirando Abajo\"\n",
    "            elif x_angle > 8:\n",
    "                text = \"Mirando Arriba\"\n",
    "            else:\n",
    "                text = \"Frente\"\n",
    "\n",
    "            # Proyectar la nariz para visualizar la dirección\n",
    "            nose_3d_projection, _ = cv2.projectPoints(\n",
    "                np.array([nose_3d]), rot_vec, trans_vec, cam_matrix, dist_matrix\n",
    "            )\n",
    "\n",
    "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "            p2 = (\n",
    "                int(nose_2d[0] + y_angle * 10),\n",
    "                int(nose_2d[1] - x_angle * 10)\n",
    "            )\n",
    "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "            # Mostrar texto\n",
    "            cv2.putText(image, text, (20, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f'x: {round(x_angle, 2)}', (20, 100),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, f'y: {round(y_angle, 2)}', (20, 130),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, f'z: {round(z_angle, 2)}', (20, 160),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Completo - Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------Sección 1: Importación de Paquetes---------------------------------\n",
    "\n",
    "\"\"\"\n",
    "En esta sección se importan todas las librerías necesarias para \n",
    "la aplicación. Entre ellas, librerías de interfaz gráfica (`tkinter`), \n",
    "visión artificial (`cv2`, `mediapipe`), librerías de utilidades como `numpy` \n",
    "y `json`, además de las librerías para el reconocimiento facial (`deepface`) \n",
    "y el modelado con YOLO (`ultralytics`). \n",
    "Por último, se maneja la configuración de logs para suprimir mensajes innecesarios.\n",
    "\"\"\"\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk, ImageSequence, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.modules import verification as df_verification\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import pygame\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#-------------------Sección 2: Funciones Auxiliares (Helper Functions)--------------------------------\n",
    "\"\"\"\n",
    "En esta sección se definen funciones sueltas que ayudan a procesar \n",
    "imágenes, dibujar texto, calcular distancias o manejar la reproducción de audio. \n",
    "Esto sirve para mantener el código más organizado.\n",
    "Copiar código\n",
    "\"\"\"\n",
    "# Mediapipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "def enhance_image_cv2(bgr_img):\n",
    "    \"\"\"Mejora la imagen BGR aplicando ecualización del canal Y (YUV).\"\"\"\n",
    "    yuv_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YUV)\n",
    "    yuv_img[:, :, 0] = cv2.equalizeHist(yuv_img[:, :, 0])\n",
    "    enhanced = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)\n",
    "    return enhanced\n",
    "\n",
    "def put_text_pil(\n",
    "    image_bgr,\n",
    "    text,\n",
    "    org=(30, 30),\n",
    "    font_path=\"arial.ttf\",\n",
    "    font_size=28,\n",
    "    color=(255, 255, 255)\n",
    "):\n",
    "    \"\"\"\n",
    "    Dibuja texto (incluyendo caracteres latinos) sobre una imagen BGR usando PIL.\n",
    "    Asegúrate de tener un archivo de fuente TrueType que soporte tildes/ñ.\n",
    "    \"\"\"\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(image_rgb)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    draw.text(org, text, font=font, fill=color)\n",
    "    image_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "    return image_bgr\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    \"\"\"Calcula la distancia Euclidiana entre dos vectores 1D de igual tamaño.\"\"\"\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "\n",
    "def manhattan_distance(vec1, vec2):\n",
    "    \"\"\"Calcula la distancia Manhattan entre dos vectores 1D de igual tamaño.\"\"\"\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return np.sum(np.abs(v1 - v2))\n",
    "\n",
    "# Sección 3: Clase Principal de la Aplicación\n",
    "\"\"\"\n",
    "Aquí se encuentra la clase `App` que encapsula toda la lógica de la interfaz gráfica, \n",
    "el control de la cámara, la detección y reconocimiento facial, la reproducción de audio, \n",
    "el manejo de registros (log) y la navegación entre pantallas de Sign Up, Login, Perfil, \n",
    "Estadísticas, etc.\n",
    "\"\"\"\n",
    "\n",
    "class App(tk.Tk):\n",
    "    \"\"\"\n",
    "    Clase principal de la aplicación de reconocimiento facial.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resizable(False, False)\n",
    "        self.title(\"Sistema de Reconocimiento Facial\")\n",
    "        self.geometry(\"800x600\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.set_num_channels(8)\n",
    "\n",
    "        self.lift()\n",
    "        self.attributes(\"-topmost\", True)\n",
    "        self.after(100, lambda: self.attributes(\"-topmost\", False))\n",
    "\n",
    "        # *** CANAL para música de fondo\n",
    "        self.channel_background = pygame.mixer.Channel(3)\n",
    "        self.background_music = None\n",
    "\n",
    "        # Modelos YOLO\n",
    "        self.yolo_model = YOLO(r\"runs\\detect\\train6\\weights\\best.pt\")  # gafas/máscara\n",
    "        self.yolo_model2 = YOLO(r\"runs\\detect\\train5\\weights\\best.pt\") # spoofing\n",
    "\n",
    "        self.channel_instructions = pygame.mixer.Channel(0)\n",
    "        self.channel_errors = pygame.mixer.Channel(1)\n",
    "\n",
    "        # Audios\n",
    "        self.camera_sound = pygame.mixer.Sound('./assets/sound/camera.mp3')\n",
    "        self.audio_creador = pygame.mixer.Sound('./assets/sound/creador.mp3')\n",
    "        self.audio_login = pygame.mixer.Sound('./assets/sound/login.mp3')\n",
    "        self.audio_ojos = pygame.mixer.Sound('./assets/sound/ojos.mp3')\n",
    "        self.audio_boca = pygame.mixer.Sound('./assets/sound/boca.mp3')\n",
    "\n",
    "        self.ultimo_sonido_ojos = 0\n",
    "        self.ultimo_sonido_boca = 0\n",
    "        self.audio_cooldown = 15\n",
    "\n",
    "        self.camera_ready = False\n",
    "        self.cap = None\n",
    "\n",
    "        # FaceMesh y FaceDetection\n",
    "        self.face_mesh = None\n",
    "        self.face_detection = None\n",
    "\n",
    "        # Atributo para saber si estamos en medio de un SignUp\n",
    "        self.in_signup_process = False\n",
    "\n",
    "        # SignUp\n",
    "        self.username = \"\"\n",
    "        self.ellipse_offsets = [(0, 0), (0, 100), (0, 200), (-150, 100), (150, 100)]\n",
    "        self.current_ellipse_index = 0\n",
    "        self.total_ellipses = len(self.ellipse_offsets)\n",
    "        self.max_images = 5\n",
    "        self.captured_count = 0\n",
    "        self.required_stable_seconds = 2.0\n",
    "        self.stable_start_time = None\n",
    "\n",
    "        # *** Se define ellipse en base al frame\n",
    "        self.fixed_rx = None\n",
    "        self.fixed_ry = None\n",
    "        self.ellipse_angle = 0\n",
    "        self.ellipse_defined_for_this_offset = False\n",
    "\n",
    "        # Login\n",
    "        self.is_logging_in = False\n",
    "        self.login_timeout_start = None\n",
    "        self.blink_count = 0\n",
    "        self.prev_eye_state = \"open\"\n",
    "        self.eye_transition_flag = False\n",
    "        self.login_image_captured = None\n",
    "        self.login_embedding_vector = None\n",
    "        self.login_start_time = None\n",
    "\n",
    "        # Usuario logueado\n",
    "        self.current_logged_in_user = None\n",
    "        self.login_image_pil = None\n",
    "        self.login_image_pil_unprocessed = None\n",
    "\n",
    "        # Simetría y predicciones\n",
    "        self.simmetry_label_var = tk.StringVar(value=\"\")\n",
    "        self.predictions_label_var = tk.StringVar(value=\"\")\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        #  MARCOS / FRAMES PRINCIPALES\n",
    "        # ---------------------------------------------------------------------\n",
    "        self.brand_video_frame = tk.Frame(self, bg=\"black\")\n",
    "        self.brand_video_frame.place(x=0, y=0, width=800, height=600)\n",
    "\n",
    "        self.video_label_intro = tk.Label(self.brand_video_frame, bg=\"black\")\n",
    "        self.video_label_intro.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        skip_button = tk.Button(\n",
    "            self.brand_video_frame,\n",
    "            text=\"Saltar Intro\",\n",
    "            command=self.skip_intro,\n",
    "            bg=\"gray\",\n",
    "            fg=\"white\"\n",
    "        )\n",
    "        skip_button.place(x=700, y=550, width=80, height=30)\n",
    "\n",
    "        self.start_frame = tk.Frame(self, bg=\"#1e1e1e\")\n",
    "        self.signup_frame = tk.Frame(self, bg=\"#1e1e1e\")\n",
    "        self.login_frame = tk.Frame(self, bg=\"#1e1e1e\")\n",
    "        self.profile_frame = tk.Frame(self, bg=\"#2c2c2c\")\n",
    "        self.stats_frame = tk.Frame(self, bg=\"#3e3e3e\")\n",
    "\n",
    "        # Label principal para cámara\n",
    "        self.video_label = tk.Label(self, bg=\"#1e1e1e\")\n",
    "\n",
    "        # Loader unificado\n",
    "        self.loader_label = tk.Label(self, bg=\"#1e1e1e\")\n",
    "        self.loader_frames = []\n",
    "        self.current_loader_frame = 0\n",
    "        loader_path = \"./assets/images/loader.gif\"\n",
    "        if os.path.exists(loader_path):\n",
    "            loader_img = Image.open(loader_path)\n",
    "            for frame in ImageSequence.Iterator(loader_img):\n",
    "                f = frame.convert(\"RGBA\")\n",
    "                self.loader_frames.append(ImageTk.PhotoImage(f))\n",
    "\n",
    "        self.flash_label = tk.Label(self, bg=\"white\")\n",
    "\n",
    "\n",
    "        self.last_spoof_box = None\n",
    "        self.spoof_lost_count = 0\n",
    "        self.spoof_lost_threshold = 5\n",
    "\n",
    "        # Hilo para cámara\n",
    "        threading.Thread(target=self.initialize_camera).start()\n",
    "\n",
    "        # Manejo de cierre de ventana\n",
    "        self.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "\n",
    "        # Intro video\n",
    "        self.intro_cap = None\n",
    "        self.intro_audio = None\n",
    "        self.is_intro_playing = True\n",
    "\n",
    "        video_path = \"./assets/images/video.mp4\"\n",
    "        audio_path = \"./assets/images/musica-inicial.mp3\"\n",
    "        self.intro_cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if os.path.exists(audio_path):\n",
    "            self.intro_audio = pygame.mixer.Sound(audio_path)\n",
    "            self.intro_channel = pygame.mixer.Channel(2)\n",
    "            self.intro_channel.play(self.intro_audio)\n",
    "\n",
    "        self.update_intro_video()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Música de fondo\n",
    "    # --------------------------------------------------------------------------\n",
    "    def play_background_music(self, music_path=\"./assets/sound/light_background_music.mp3\", volume=0.2):\n",
    "        \"\"\"Inicia la música de fondo en bucle con cierto volumen.\"\"\"\n",
    "        if not os.path.exists(music_path):\n",
    "            return\n",
    "        if self.background_music is None:\n",
    "            self.background_music = pygame.mixer.Sound(music_path)\n",
    "        self.background_music.set_volume(volume)\n",
    "        self.channel_background.play(self.background_music, loops=-1)\n",
    "\n",
    "    def stop_background_music(self):\n",
    "        \"\"\"Detiene la música de fondo.\"\"\"\n",
    "        if self.channel_background.get_busy():\n",
    "            self.channel_background.stop()\n",
    "\n",
    "    def pause_background_music(self):\n",
    "        \"\"\"Pausa la música de fondo (si está reproduciendo).\"\"\"\n",
    "        if self.channel_background.get_busy():\n",
    "            self.channel_background.pause()\n",
    "\n",
    "    def resume_background_music(self):\n",
    "        \"\"\"Resume la música de fondo (si estaba en pausa).\"\"\"\n",
    "        if not self.channel_background.get_busy():\n",
    "            self.channel_background.play(self.background_music, loops=-1)\n",
    "        else:\n",
    "            self.channel_background.unpause()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Eventos de cierre\n",
    "    # --------------------------------------------------------------------------\n",
    "    def on_closing(self):\n",
    "        # Detén todos los canales que has utilizado:\n",
    "        self.channel_instructions.stop()\n",
    "        self.channel_errors.stop()\n",
    "        if hasattr(self, 'intro_channel'):\n",
    "            self.intro_channel.stop()\n",
    "        \n",
    "        # Además de tu música de fondo\n",
    "        self.stop_background_music()\n",
    "        \n",
    "        #Se limpian los labels\n",
    "        self.simmetry_label_var = tk.StringVar(value=\"\")\n",
    "        self.predictions_label_var = tk.StringVar(value=\"\")\n",
    "\n",
    "        # Resto de tareas de limpieza\n",
    "        if self.in_signup_process:\n",
    "            self.cancel_signup()\n",
    "        if self.cap and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "        self.destroy()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Loader (GIF)\n",
    "    # --------------------------------------------------------------------------\n",
    "    def animate_loader(self):\n",
    "        if not self.loader_frames:\n",
    "            return\n",
    "        frame = self.loader_frames[self.current_loader_frame]\n",
    "        self.loader_label.config(image=frame)\n",
    "        self.current_loader_frame = (self.current_loader_frame + 1) % len(self.loader_frames)\n",
    "        self.after(100, self.animate_loader)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Intro Video\n",
    "    # --------------------------------------------------------------------------\n",
    "    def update_intro_video(self):\n",
    "        if not self.intro_cap:\n",
    "            self.finish_intro()\n",
    "            return\n",
    "\n",
    "        ret, frame = self.intro_cap.read()\n",
    "        if not ret:\n",
    "            self.finish_intro()\n",
    "            return\n",
    "\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        imgtk = ImageTk.PhotoImage(Image.fromarray(frame_rgb))\n",
    "        self.video_label_intro.imgtk = imgtk\n",
    "        self.video_label_intro.configure(image=imgtk)\n",
    "\n",
    "        self.video_label_intro.after(33, self.update_intro_video)\n",
    "\n",
    "    def finish_intro(self):\n",
    "        \"\"\"Se llama cuando termina el video de introducción.\"\"\"\n",
    "        self.is_intro_playing = False\n",
    "        if self.intro_audio:\n",
    "            self.intro_channel.stop()\n",
    "        if self.intro_cap:\n",
    "            self.intro_cap.release()\n",
    "        self.intro_cap = None\n",
    "\n",
    "        self.brand_video_frame.place_forget()\n",
    "        self.create_start_frame_gui()\n",
    "        self.start_frame.place(x=0, y=0, width=800, height=600)\n",
    "\n",
    "        self.play_background_music(volume=0.2)\n",
    "\n",
    "    def skip_intro(self):\n",
    "        \"\"\"Si el usuario presiona 'Saltar Intro' antes de terminar el video.\"\"\"\n",
    "        self.is_intro_playing = False\n",
    "        if self.intro_audio:\n",
    "            self.intro_channel.stop()\n",
    "        if self.intro_cap:\n",
    "            self.intro_cap.release()\n",
    "        self.intro_cap = None\n",
    "\n",
    "        self.brand_video_frame.place_forget()\n",
    "        self.create_start_frame_gui()\n",
    "        self.start_frame.place(x=0, y=0, width=800, height=600)\n",
    "\n",
    "        self.play_background_music(volume=0.2)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Pantalla inicial\n",
    "    # --------------------------------------------------------------------------\n",
    "    def create_start_frame_gui(self):\n",
    "        \"\"\"Construye la pantalla inicial de la app (botones Login y SignUp).\"\"\"\n",
    "        if hasattr(self, \"start_content_created\") and self.start_content_created:\n",
    "            return\n",
    "        self.start_content_created = True\n",
    "\n",
    "        try:\n",
    "            bg_img = Image.open(\"./assets/images/background.png\")\n",
    "            self.bg_photo = ImageTk.PhotoImage(bg_img)\n",
    "            bg_label = tk.Label(self.start_frame, image=self.bg_photo)\n",
    "            bg_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        title_label = tk.Label(\n",
    "            self.start_frame,\n",
    "            text=\"Bienvenido al Sistema de Reconocimiento Facial\",\n",
    "            font=(\"Helvetica\", 18, \"bold\"),\n",
    "            fg=\"#ffffff\",\n",
    "            bg=\"#3d7a9e\"\n",
    "        )\n",
    "        title_label.place(relx=0.5, rely=0.2, anchor=\"center\")\n",
    "\n",
    "        try:\n",
    "            img_login_btn = Image.open(\"./assets/images/login1.png\")\n",
    "            img_signup_btn = Image.open(\"./assets/images/register1.png\")\n",
    "            img_login_btn = img_login_btn.resize((180, 190), Image.Resampling.LANCZOS)\n",
    "            img_signup_btn = img_signup_btn.resize((180, 190), Image.Resampling.LANCZOS)\n",
    "\n",
    "            self.img_login_btn = ImageTk.PhotoImage(img_login_btn)\n",
    "            self.img_signup_btn = ImageTk.PhotoImage(img_signup_btn)\n",
    "\n",
    "            btn_login = tk.Button(\n",
    "                self.start_frame,\n",
    "                image=self.img_login_btn,\n",
    "                command=self.go_to_login,\n",
    "                bg=\"#3d7a9e\",\n",
    "                bd=0,\n",
    "                activebackground=\"#3d7a9e\",\n",
    "                relief=\"flat\"\n",
    "            )\n",
    "            btn_login.place(relx=0.2, rely=0.5, anchor=\"center\")\n",
    "\n",
    "            btn_signup = tk.Button(\n",
    "                self.start_frame,\n",
    "                image=self.img_signup_btn,\n",
    "                command=self.go_to_signup,\n",
    "                bg=\"#3d7a9e\",\n",
    "                bd=0,\n",
    "                activebackground=\"#3d7a9e\",\n",
    "                relief=\"flat\"\n",
    "            )\n",
    "            btn_signup.place(relx=0.8, rely=0.5, anchor=\"center\")\n",
    "        except:\n",
    "            # Si no hay imágenes, muestra texto\n",
    "            btn_login = tk.Button(\n",
    "                self.start_frame,\n",
    "                text=\"Log In\",\n",
    "                command=self.go_to_login,\n",
    "                font=(\"Helvetica\", 14),\n",
    "                bg=\"#00aaff\",\n",
    "                fg=\"#ffffff\",\n",
    "                bd=0,\n",
    "                relief=\"flat\",\n",
    "                padx=20,\n",
    "                pady=10\n",
    "            )\n",
    "            btn_login.place(relx=0.2, rely=0.5, anchor=\"center\")\n",
    "\n",
    "            btn_signup = tk.Button(\n",
    "                self.start_frame,\n",
    "                text=\"Sign Up\",\n",
    "                command=self.go_to_signup,\n",
    "                font=(\"Helvetica\", 14),\n",
    "                bg=\"#00aaff\",\n",
    "                fg=\"#ffffff\",\n",
    "                bd=0,\n",
    "                relief=\"flat\",\n",
    "                padx=20,\n",
    "                pady=10\n",
    "            )\n",
    "            btn_signup.place(relx=0.8, rely=0.5, anchor=\"center\")\n",
    "\n",
    "    def initialize_camera(self):\n",
    "        \"\"\"Inicializa la cámara y crea los objetos de Mediapipe.\"\"\"\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "        if not self.cap.isOpened():\n",
    "            self.camera_ready = False\n",
    "            return\n",
    "\n",
    "        mp_face_mesh_module = mp.solutions.face_mesh\n",
    "        self.face_mesh = mp_face_mesh_module.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        mp_face_detection = mp.solutions.face_detection\n",
    "        self.face_detection = mp_face_detection.FaceDetection(\n",
    "            model_selection=0,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "\n",
    "        self.camera_ready = True\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # SIGNUP\n",
    "    # ---------------------------------------------------------------\n",
    "    def go_to_signup(self):\n",
    "        \"\"\"Cambia a la pantalla de registro (SignUp).\"\"\"\n",
    "        self.blink_count = 0\n",
    "        self.start_frame.place_forget()\n",
    "        self.setup_signup_frame()\n",
    "        self.signup_frame.place(x=0, y=0, width=800, height=600)\n",
    "\n",
    "    def setup_signup_frame(self):\n",
    "        \"\"\"Construye el contenido de la pantalla de registro (SignUp).\"\"\"\n",
    "        if hasattr(self, 'signup_content_created') and self.signup_content_created:\n",
    "            return\n",
    "        self.signup_content_created = True\n",
    "\n",
    "        lbl_title = tk.Label(\n",
    "            self.signup_frame,\n",
    "            text=\"Register\",\n",
    "            font=(\"Helvetica\", 16),\n",
    "            fg=\"#ffffff\",\n",
    "            bg=\"#1e1e1e\"\n",
    "        )\n",
    "        lbl_title.pack(pady=10)\n",
    "\n",
    "        frm_inner = tk.Frame(self.signup_frame, bg=\"#1e1e1e\")\n",
    "        frm_inner.pack(pady=20)\n",
    "\n",
    "        tk.Label(\n",
    "            frm_inner,\n",
    "            text=\"Ingrese su nombre de usuario:\",\n",
    "            font=(\"Helvetica\", 12),\n",
    "            fg=\"#ffffff\",\n",
    "            bg=\"#1e1e1e\"\n",
    "        ).grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.username_entry = tk.Entry(frm_inner, font=(\"Helvetica\", 12))\n",
    "        self.username_entry.grid(row=1, column=0, padx=10, pady=5)\n",
    "\n",
    "        tk.Button(\n",
    "            frm_inner,\n",
    "            text=\"Aceptar\",\n",
    "            command=self.start_signup,\n",
    "            font=(\"Helvetica\", 12),\n",
    "            bg=\"#00aaff\",\n",
    "            fg=\"#ffffff\",\n",
    "            bd=0,\n",
    "            relief=\"flat\",\n",
    "            padx=10,\n",
    "            pady=5\n",
    "        ).grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.btn_cancelar_signup = tk.Button(\n",
    "            self.signup_frame,\n",
    "            text=\"Cancelar\",\n",
    "            font=(\"Helvetica\", 12),\n",
    "            bg=\"#ff6666\",\n",
    "            fg=\"#ffffff\",\n",
    "            command=self.cancel_signup\n",
    "        )\n",
    "        self.btn_cancelar_signup.pack(side=\"bottom\", pady=10)\n",
    "\n",
    "    def start_signup(self):\n",
    "        \"\"\"Valida nombre de usuario y prepara la cámara para el proceso de SignUp.\"\"\"\n",
    "        username = self.username_entry.get().strip()\n",
    "        if username == \"\":\n",
    "            messagebox.showerror(\"Error\", \"Por favor, ingrese un nombre de usuario.\")\n",
    "            return\n",
    "\n",
    "        self.username = username\n",
    "        if os.path.exists(f'usuarios/{self.username}'):\n",
    "            messagebox.showerror(\"Error\", f\"El usuario '{self.username}' ya existe. Elija otro.\")\n",
    "            return\n",
    "        else:\n",
    "            os.makedirs(f'usuarios/{self.username}')\n",
    "\n",
    "        self.in_signup_process = True\n",
    "        self.current_ellipse_index = 0\n",
    "        self.captured_count = 0\n",
    "        self.stable_start_time = None\n",
    "        self.ellipse_defined_for_this_offset = False\n",
    "\n",
    "        self.loader_label.place(in_=self.signup_frame, relx=0.5, rely=0.5, anchor=\"center\")\n",
    "        self.animate_loader()\n",
    "        self.signup_start_time = time.time()\n",
    "        self.check_camera_ready_signup()\n",
    "\n",
    "    def check_camera_ready_signup(self):\n",
    "        \"\"\"Revisa si la cámara está lista para iniciar SignUp.\"\"\"\n",
    "        if self.camera_ready:\n",
    "            self.loader_label.place_forget()\n",
    "            self.start_signup_camera()\n",
    "        else:\n",
    "            if time.time() - self.signup_start_time > 60:\n",
    "                messagebox.showerror(\"Error\", \"No se pudo acceder a la cámara (time-out).\")\n",
    "                self.return_to_start()\n",
    "                return\n",
    "            else:\n",
    "                self.after(100, self.check_camera_ready_signup)\n",
    "\n",
    "    def start_signup_camera(self):\n",
    "        \"\"\"Inicia la cámara en la pantalla de registro.\"\"\"\n",
    "        self.signup_frame.place(x=0, y=0, width=800, height=600)\n",
    "        self.video_label.place(x=0, y=0, width=800, height=600, in_=self.signup_frame)\n",
    "\n",
    "        # Evitar solapamiento: si ya suena algo, no reproducir\n",
    "        if (not self.channel_instructions.get_busy()) and (not self.channel_errors.get_busy()):\n",
    "            self.pause_background_music()\n",
    "            self.channel_instructions.play(self.audio_creador)\n",
    "            dur = self.audio_creador.get_length()\n",
    "            self.after(int(dur*1000), self.resume_background_music)\n",
    "\n",
    "        self.update_frame_signup()\n",
    "\n",
    "    def cancel_signup(self):\n",
    "        \"\"\"Cancela el registro y elimina la carpeta del usuario si existe.\"\"\"\n",
    "        if self.username:\n",
    "            user_folder = f\"usuarios/{self.username}\"\n",
    "            if os.path.exists(user_folder):\n",
    "                try:\n",
    "                    shutil.rmtree(user_folder)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al eliminar carpeta: {e}\")\n",
    "        self.username = \"\"\n",
    "        self.in_signup_process = False\n",
    "        self.return_to_start()\n",
    "\n",
    "    def update_frame_signup(self):\n",
    "        \"\"\"Loop de lectura de cámara para SignUp.\"\"\"\n",
    "        if (self.cap is None) or (self.captured_count >= self.max_images):\n",
    "            return\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.video_label.after(10, self.update_frame_signup)\n",
    "            return\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = self.resize_for_label(frame, (800, 600))\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Detección de cara (Mediapipe Face Detection)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detection_results = self.face_detection.process(rgb_frame)\n",
    "\n",
    "        one_face = False\n",
    "        face_box = None\n",
    "\n",
    "        if detection_results.detections and len(detection_results.detections) == 1:\n",
    "            one_face = True\n",
    "            detection = detection_results.detections[0]\n",
    "            box = detection.location_data.relative_bounding_box\n",
    "            x_min = int(box.xmin * w)\n",
    "            y_min = int(box.ymin * h)\n",
    "            x_max = x_min + int(box.width * w)\n",
    "            y_max = y_min + int(box.height * h)\n",
    "            face_box = (x_min, y_min, x_max, y_max)\n",
    "\n",
    "        # YOLO gafas/máscara\n",
    "        found_glasses_mask = False\n",
    "        boxes_gm = []\n",
    "        if one_face and face_box is not None:\n",
    "            fx1, fy1, fx2, fy2 = face_box\n",
    "            fx1 = max(0, fx1); fy1 = max(0, fy1)\n",
    "            fx2 = min(w, fx2); fy2 = min(h, fy2)\n",
    "            face_roi = frame[fy1:fy2, fx1:fx2]\n",
    "            if face_roi.size > 0:\n",
    "                face_640 = cv2.resize(face_roi, (640, 640))\n",
    "                results = self.yolo_model.predict(face_640, imgsz=640, conf=0.25, verbose=False)\n",
    "                for r in results:\n",
    "                    for box_yolo in r.boxes:\n",
    "                        cls_id = int(box_yolo.cls[0])\n",
    "                        class_name = r.names[cls_id].lower()\n",
    "                        if class_name not in [\"glasses\", \"mask\"]:\n",
    "                            continue\n",
    "                        found_glasses_mask = True\n",
    "\n",
    "                        x1_640, y1_640 = int(box_yolo.xyxy[0][0]), int(box_yolo.xyxy[0][1])\n",
    "                        x2_640, y2_640 = int(box_yolo.xyxy[0][2]), int(box_yolo.xyxy[0][3])\n",
    "                        face_w = fx2 - fx1\n",
    "                        face_h = fy2 - fy1\n",
    "                        scale_x = face_w / 640.0\n",
    "                        scale_y = face_h / 640.0\n",
    "\n",
    "                        bx1 = fx1 + int(x1_640 * scale_x)\n",
    "                        by1 = fy1 + int(y1_640 * scale_y)\n",
    "                        bx2 = fx1 + int(x2_640 * scale_x)\n",
    "                        by2 = fy1 + int(y2_640 * scale_y)\n",
    "                        boxes_gm.append((bx1, by1, bx2, by2, class_name))\n",
    "\n",
    "\n",
    "\n",
    "        # Dibujar boxes gafas/máscara\n",
    "        for (x1_gm, y1_gm, x2_gm, y2_gm, cname) in boxes_gm:\n",
    "            color = (0, 255, 255) if cname == \"glasses\" else (255, 0, 255)\n",
    "            cv2.rectangle(frame, (x1_gm, y1_gm), (x2_gm, y2_gm), color, 2)\n",
    "            frame = put_text_pil(frame, cname, (x1_gm, y1_gm - 35), font_size=28, color=color)\n",
    "\n",
    "\n",
    "        # Mensajes si gafas/máscara o spoof\n",
    "        font_scale_cv = 1.3\n",
    "        if found_glasses_mask:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"Debe quitarse gafas/mascara\",\n",
    "                (30, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale_cv,\n",
    "                (0, 0, 255),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        if found_glasses_mask:\n",
    "            self.show_frame_on_label(frame)\n",
    "            self.video_label.after(10, self.update_frame_signup)\n",
    "            return\n",
    "\n",
    "        # Analizar FaceMesh para:\n",
    "        # - Head pose\n",
    "        # - Saber si la cara está en el óvalo con la malla (mesh points)\n",
    "        mesh_results = self.face_mesh.process(rgb_frame)\n",
    "        head_pose_text = \"Undefined\"\n",
    "        head_is_forward = False\n",
    "        head_pose_color = (255, 0, 0)  # color por defecto\n",
    "\n",
    "        if mesh_results.multi_face_landmarks and len(mesh_results.multi_face_landmarks) == 1:\n",
    "            face_landmarks = mesh_results.multi_face_landmarks[0]\n",
    "            face_3d = []\n",
    "            face_2d = []\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx in [33, 263, 1, 61, 291, 199]:\n",
    "                    xx, yy = int(lm.x * w), int(lm.y * h)\n",
    "                    face_2d.append([xx, yy])\n",
    "                    face_3d.append([xx, yy, lm.z])\n",
    "            if len(face_2d) == 6:\n",
    "                focal_length = w\n",
    "                cam_matrix = np.array([[focal_length,0,h/2],\n",
    "                                       [0,focal_length,w/2],\n",
    "                                       [0,0,1]])\n",
    "                dist_matrix = np.zeros((4,1), dtype=np.float64)\n",
    "                success_pnp, rot_vec, trans_vec = cv2.solvePnP(\n",
    "                    np.array(face_3d, dtype=np.float64),\n",
    "                    np.array(face_2d, dtype=np.float64),\n",
    "                    cam_matrix,\n",
    "                    dist_matrix\n",
    "                )\n",
    "                if success_pnp:\n",
    "                    rmat, _ = cv2.Rodrigues(rot_vec)\n",
    "                    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rmat)\n",
    "                    x_angle = angles[0]*360\n",
    "                    y_angle = angles[1]*360\n",
    "                    if y_angle < -4:\n",
    "                        head_pose_text = \"Mirando Izq.\"\n",
    "                    elif y_angle > 5:\n",
    "                        head_pose_text = \"Mirando Der.\"\n",
    "                    elif x_angle < -3:\n",
    "                        head_pose_text = \"Mirando Abajo\"\n",
    "                    elif x_angle > 8:\n",
    "                        head_pose_text = \"Mirando Arriba\"\n",
    "                    else:\n",
    "                        head_pose_text = \"Frente\"\n",
    "                        head_is_forward = True\n",
    "\n",
    "        # Determinar color de la pose\n",
    "        head_pose_color = (0, 255, 0) if head_is_forward else (255, 0, 0)\n",
    "        # Mostrar texto de la pose\n",
    "        head_full_text = f\"Pos. Cabeza: {head_pose_text}\"\n",
    "        frame = put_text_pil(frame, head_full_text, (30, 100), font_size=28, color=head_pose_color)\n",
    "\n",
    "        # Óvalo + ojos y boca\n",
    "        if one_face and mesh_results.multi_face_landmarks and len(mesh_results.multi_face_landmarks) == 1:\n",
    "            if not self.ellipse_defined_for_this_offset:\n",
    "                self.define_ellipse_for_current_offset(face_box, (w,h))\n",
    "                self.ellipse_defined_for_this_offset = True\n",
    "\n",
    "            # Calculamos 4 puntos (top, bottom, left, right) de la mesh\n",
    "            # para verificar con is_face_inside_rotated_ellipse_mesh\n",
    "            face_landmarks = mesh_results.multi_face_landmarks[0]\n",
    "            xs = []\n",
    "            ys = []\n",
    "            for lm in face_landmarks.landmark:\n",
    "                xs.append(int(lm.x * w))\n",
    "                ys.append(int(lm.y * h))\n",
    "\n",
    "            x_left   = min(xs)\n",
    "            x_right  = max(xs)\n",
    "            y_top    = min(ys)\n",
    "            y_bottom = max(ys)\n",
    "\n",
    "            pt_top    = ((x_left + x_right)//2, y_top)\n",
    "            pt_bottom = ((x_left + x_right)//2, y_bottom)\n",
    "            pt_left   = (x_left, (y_top + y_bottom)//2)\n",
    "            pt_right  = (x_right, (y_top + y_bottom)//2)\n",
    "            mesh_points = [pt_top, pt_bottom, pt_left, pt_right]\n",
    "\n",
    "            cx, cy, rx, ry = self.current_ellipse\n",
    "            face_inside = self.is_face_inside_rotated_ellipse_mesh(\n",
    "                mesh_points, \n",
    "                cx, \n",
    "                cy, \n",
    "                rx, \n",
    "                ry, \n",
    "                self.ellipse_angle\n",
    "            )\n",
    "\n",
    "            # Comprobamos ojos y boca\n",
    "            eyes_open = False\n",
    "            mouth_closed = False\n",
    "\n",
    "            if head_is_forward:\n",
    "                landmarks = face_landmarks.landmark\n",
    "                left_eye_indices = [33,160,158,133,153,144]\n",
    "                right_eye_indices= [362,385,387,263,373,380]\n",
    "                left_eye_coords = [(int(landmarks[i].x*w), int(landmarks[i].y*h)) for i in left_eye_indices]\n",
    "                right_eye_coords= [(int(landmarks[i].x*w),int(landmarks[i].y*h)) for i in right_eye_indices]\n",
    "                left_EAR = self.calculate_EAR(left_eye_coords)\n",
    "                right_EAR= self.calculate_EAR(right_eye_coords)\n",
    "                EAR_thr = 0.2\n",
    "                if (left_EAR>=EAR_thr) and (right_EAR>=EAR_thr):\n",
    "                    eyes_open=True\n",
    "\n",
    "                # Boca\n",
    "                mt_idx, mb_idx = 13, 14\n",
    "                mt = (int(landmarks[mt_idx].x*w), int(landmarks[mt_idx].y*h))\n",
    "                mb = (int(landmarks[mb_idx].x*w), int(landmarks[mb_idx].y*h))\n",
    "                dist_mouth = np.linalg.norm(np.array(mt)-np.array(mb))\n",
    "                mouth_closed = (dist_mouth<=30)\n",
    "\n",
    "            conditions_ok = (face_inside and eyes_open and mouth_closed and head_is_forward)\n",
    "            ellipse_color = (0,0,255)\n",
    "\n",
    "            if conditions_ok:\n",
    "                ellipse_color = (0,255,0)\n",
    "                if self.stable_start_time is None:\n",
    "                    self.stable_start_time = time.time()\n",
    "                stable_time = time.time() - self.stable_start_time\n",
    "\n",
    "                msg_estable = f\"Estable: {stable_time:.1f} seg\"\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    msg_estable,\n",
    "                    (30, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.3,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                if stable_time >= self.required_stable_seconds:\n",
    "                    # Capturamos foto\n",
    "                    if self.channel_instructions.get_busy():\n",
    "                        self.channel_instructions.stop()\n",
    "                    if self.channel_errors.get_busy():\n",
    "                        self.channel_errors.stop()\n",
    "\n",
    "                    self.capture_and_crop_face(face_box, True)\n",
    "                    self.show_flash_effect()\n",
    "                    self.pause_background_music()\n",
    "                    self.camera_sound.play()\n",
    "                    dur_cam = self.camera_sound.get_length()\n",
    "                    self.after(int(dur_cam*1000), self.resume_background_music)\n",
    "\n",
    "                    self.current_ellipse_index += 1\n",
    "                    self.captured_count += 1\n",
    "                    self.ellipse_defined_for_this_offset = False\n",
    "                    self.stable_start_time = None\n",
    "\n",
    "                    if (self.captured_count>=self.max_images or\n",
    "                        self.current_ellipse_index>=self.total_ellipses):\n",
    "                        self.finish_signup_captures()\n",
    "                        return\n",
    "            else:\n",
    "                # Mostrar razones\n",
    "                reasons=[]\n",
    "                if not face_inside: reasons.append(\"Cara fuera del ovalo (mesh)\")\n",
    "                if not eyes_open: reasons.append(\"Ojos cerrados\")\n",
    "                if not mouth_closed: reasons.append(\"Boca abierta\")\n",
    "                if not head_is_forward: reasons.append(\"Cabeza no de frente\")\n",
    "\n",
    "                if reasons:\n",
    "                    msg_err = \"Condiciones no cumplidas:\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        msg_err,\n",
    "                        (int(w/2), 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.9,\n",
    "                        (0, 0, 255),\n",
    "                        2\n",
    "                    )\n",
    "                    y_offset = 70\n",
    "                    for reason in reasons:\n",
    "                        cv2.putText(\n",
    "                            frame,\n",
    "                            reason,\n",
    "                            (int(w/2 + 20), y_offset),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.9,\n",
    "                            (0, 0, 255),\n",
    "                            2\n",
    "                        )\n",
    "                        y_offset += 30\n",
    "                self.handle_error_sounds(eyes_open, mouth_closed)\n",
    "                self.stable_start_time=None\n",
    "\n",
    "            cv2.ellipse(frame,(cx,cy),(rx,ry),self.ellipse_angle,0,360,ellipse_color,2)\n",
    "\n",
    "        else:\n",
    "            # Mensaje \"No se detecta ninguna cara...\"\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"No se detecta ninguna cara...\",\n",
    "                (30, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.1,\n",
    "                (0,0,255),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        # Dibujar FaceMesh en pantalla\n",
    "        if mesh_results.multi_face_landmarks:\n",
    "            for face_landmarks in mesh_results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=drawing_spec,\n",
    "                    connection_drawing_spec=drawing_spec\n",
    "                )\n",
    "\n",
    "        self.show_frame_on_label(frame)\n",
    "        self.video_label.after(10, self.update_frame_signup)\n",
    "\n",
    "    def capture_and_crop_face(self, face_box, is_signup=False):\n",
    "        \"\"\"Captura frame actual, recorta cara y guarda si is_signup=True.\"\"\"\n",
    "        ret, raw_frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "        raw_frame = cv2.flip(raw_frame,1)\n",
    "        raw_frame = self.resize_for_label(raw_frame,(800,600))\n",
    "\n",
    "        x_min, y_min, x_max, y_max = face_box\n",
    "        hh, ww, _ = raw_frame.shape\n",
    "        x_min = max(0,x_min); y_min = max(0,y_min)\n",
    "        x_max = min(ww,x_max); y_max = min(hh,y_max)\n",
    "        face_unprocessed = raw_frame[y_min:y_max, x_min:x_max]\n",
    "        if face_unprocessed.size==0:\n",
    "            return\n",
    "        \n",
    "\n",
    "        face_processed = enhance_image_cv2(face_unprocessed)\n",
    "\n",
    "        if is_signup:\n",
    "            img_count = self.captured_count+1\n",
    "            base_path = f\"usuarios/{self.username}\"\n",
    "            unp_path = os.path.join(base_path,f\"foto_{img_count}_unproc.png\")\n",
    "            pro_path = os.path.join(base_path,f\"foto_{img_count}.png\")\n",
    "\n",
    "            pil_unproc = Image.fromarray(cv2.cvtColor(face_unprocessed,cv2.COLOR_BGR2RGB))\n",
    "            pil_unproc.save(unp_path)\n",
    "            pil_proc = Image.fromarray(cv2.cvtColor(face_processed,cv2.COLOR_BGR2RGB))\n",
    "            pil_proc.save(pro_path)\n",
    "\n",
    "    def finish_signup_captures(self):\n",
    "        \"\"\"Genera embeddings y finaliza signup.\"\"\"\n",
    "        self.generate_embeddings()\n",
    "        messagebox.showinfo(\n",
    "            \"Sign Up\",\n",
    "            f\"Se han capturado {self.captured_count} imágenes. Registro completado para {self.username}!\"\n",
    "        )\n",
    "        self.on_signup_complete()\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        \"\"\"Genera embeddings Facenet de las fotos capturadas en SignUp.\"\"\"\n",
    "        user_folder = f\"usuarios/{self.username}\"\n",
    "        embeddings_list = []\n",
    "        for i in range(1,self.captured_count+1):\n",
    "            img_path = os.path.join(user_folder,f\"foto_{i}.png\")\n",
    "            if os.path.exists(img_path):\n",
    "                emb_data = DeepFace.represent(img_path=img_path,model_name=\"Facenet\",enforce_detection=False)\n",
    "                if(len(emb_data)>0)and(\"embedding\" in emb_data[0]):\n",
    "                    arr = np.array(emb_data[0][\"embedding\"]).flatten()\n",
    "                    if arr.shape[0]==128:\n",
    "                        embeddings_list.append(arr.tolist())\n",
    "        data={\"username\":self.username,\"embeddings\":embeddings_list}\n",
    "        with open(os.path.join(user_folder,\"embeddings.json\"),\"w\") as f:\n",
    "            json.dump(data,f,indent=2)\n",
    "\n",
    "    def on_signup_complete(self):\n",
    "        \"\"\"Retorna a start tras completar signup.\"\"\"\n",
    "        self.username=\"\"\n",
    "        self.in_signup_process=False\n",
    "        self.video_label.place_forget()\n",
    "        self.return_to_start()\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # LOGIN\n",
    "    # ---------------------------------------------------------------\n",
    "    def go_to_login(self):\n",
    "        \"\"\"Cambia a la pantalla de Login.\"\"\"\n",
    "        self.blink_count=0\n",
    "        self.start_frame.place_forget()\n",
    "        self.setup_login_frame()\n",
    "        self.login_frame.place(x=0, y=0, width=800, height=600)\n",
    "\n",
    "        self.login_timeout_start=time.time()\n",
    "        self.blink_count=0\n",
    "        self.prev_eye_state=\"open\"\n",
    "        self.eye_transition_flag=False\n",
    "        self.login_image_captured=None\n",
    "        self.login_embedding_vector=None\n",
    "        self.current_logged_in_user=None\n",
    "        self.login_image_pil=None\n",
    "        self.login_image_pil_unprocessed=None\n",
    "\n",
    "        self.loader_label.place(in_=self.login_frame, relx=0.5, rely=0.5, anchor=\"center\")\n",
    "        self.animate_loader()\n",
    "        self.check_camera_ready_login()\n",
    "\n",
    "    def setup_login_frame(self):\n",
    "        if hasattr(self,'login_content_created') and self.login_content_created:\n",
    "            return\n",
    "        self.login_content_created=True\n",
    "\n",
    "        lbl_title=tk.Label(self.login_frame,text=\"Login\",font=(\"Helvetica\",16),\n",
    "                           fg=\"#ffffff\",bg=\"#1e1e1e\")\n",
    "        lbl_title.pack(pady=10)\n",
    "\n",
    "        btn_volver=tk.Button(self.login_frame,text=\"Volver\",\n",
    "                             font=(\"Helvetica\",12),bg=\"#ff6666\",fg=\"#ffffff\",\n",
    "                             command=self.return_to_start)\n",
    "        btn_volver.place(relx=0.5,rely=1.0,anchor=\"s\",y=-10,in_=self.login_frame)\n",
    "\n",
    "    def check_camera_ready_login(self):\n",
    "        \"\"\"Revisa cámara para login.\"\"\"\n",
    "        if self.camera_ready:\n",
    "            self.loader_label.place_forget()\n",
    "            self.video_label.place(x=0,y=0,width=800,height=600,in_=self.login_frame)\n",
    "            self.start_login_process()\n",
    "        else:\n",
    "            if time.time()-self.login_timeout_start>60:\n",
    "                self.loader_label.place_forget()\n",
    "                messagebox.showerror(\"Error\",\"No se pudo acceder a la cámara (time-out).\")\n",
    "                self.return_to_start()\n",
    "                return\n",
    "            self.after(100,self.check_camera_ready_login)\n",
    "\n",
    "    def start_login_process(self):\n",
    "        \"\"\"Inicia la captura de cámara para login.\"\"\"\n",
    "        self.is_logging_in=True\n",
    "        self.login_start_time=time.time()\n",
    "\n",
    "        # Evitar solapamiento de audio\n",
    "        if (not self.channel_instructions.get_busy()) and (not self.channel_errors.get_busy()):\n",
    "            self.pause_background_music()\n",
    "            self.channel_instructions.play(self.audio_login)\n",
    "            dur = self.audio_login.get_length()\n",
    "            self.after(int(dur*1000), self.resume_background_music)\n",
    "\n",
    "        self.update_frame_login()\n",
    "\n",
    "    def update_frame_login(self):\n",
    "        \"\"\"Loop de cámara para login.\"\"\"\n",
    "        if not self.is_logging_in or (self.cap is None):\n",
    "            return\n",
    "\n",
    "        ret,frame=self.cap.read()\n",
    "        if not ret:\n",
    "            self.video_label.after(10,self.update_frame_login)\n",
    "            return\n",
    "\n",
    "        clean_frame=frame.copy()\n",
    "        frame=cv2.flip(frame,1)\n",
    "        clean_frame=cv2.flip(clean_frame,1)\n",
    "\n",
    "        frame=self.resize_for_label(frame,(800,600))\n",
    "        clean_frame=self.resize_for_label(clean_frame,(800,600))\n",
    "        h,w,_=frame.shape\n",
    "\n",
    "        font_scale_cv = 1.3\n",
    "\n",
    "        # Spoofing\n",
    "        frame_640=cv2.resize(frame,(640,640))\n",
    "        results_spoof=self.yolo_model2.predict(frame_640,imgsz=640,conf=0.25,verbose=False)\n",
    "\n",
    "        boxes_spoof=[]\n",
    "        found_restriction=False\n",
    "        class_name2=\"\"  # para mostrar texto\n",
    "\n",
    "        for r2 in results_spoof:\n",
    "            for box2 in r2.boxes:\n",
    "                cls2_id=int(box2.cls[0])\n",
    "                class_name2=r2.names[cls2_id]\n",
    "                if class_name2 in[\"Device\",\"Masks\",\"Photo\"]:\n",
    "                    x1_640,y1_640=int(box2.xyxy[0][0]),int(box2.xyxy[0][1])\n",
    "                    x2_640,y2_640=int(box2.xyxy[0][2]),int(box2.xyxy[0][3])\n",
    "                    scale_x=w/640.0\n",
    "                    scale_y=h/640.0\n",
    "                    x1=int(x1_640*scale_x)\n",
    "                    y1=int(y1_640*scale_y)\n",
    "                    x2=int(x2_640*scale_x)\n",
    "                    y2=int(y2_640*scale_y)\n",
    "                    boxes_spoof.append((x1,y1,x2,y2))\n",
    "\n",
    "        if boxes_spoof:\n",
    "            self.spoof_lost_count=0\n",
    "            self.last_spoof_box=boxes_spoof[0]\n",
    "        else:\n",
    "            if self.last_spoof_box is not None:\n",
    "                self.spoof_lost_count+=1\n",
    "                if self.spoof_lost_count<self.spoof_lost_threshold:\n",
    "                    boxes_spoof.append(self.last_spoof_box)\n",
    "                else:\n",
    "                    self.last_spoof_box=None\n",
    "\n",
    "        for(sx1,sy1,sx2,sy2)in boxes_spoof:\n",
    "            cv2.rectangle(frame,(sx1,sy1),(sx2,sy2),(0,0,255),2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"Spoofing Detectado\",\n",
    "                (sx2,sy1),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale_cv,\n",
    "                (0,0,255),\n",
    "                2\n",
    "            )\n",
    "            found_restriction=True\n",
    "\n",
    "        # Mediapipe face detection\n",
    "        rgb_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        detection_results=self.face_detection.process(rgb_frame)\n",
    "\n",
    "        # YOLO gafas/máscara\n",
    "        if detection_results.detections:\n",
    "            if len(detection_results.detections)>1:\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    \"Debe haber 1 sola cara\",\n",
    "                    (30,90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    font_scale_cv,\n",
    "                    (0,0,255),\n",
    "                    2\n",
    "                )\n",
    "                found_restriction=True\n",
    "            else:\n",
    "                detection=detection_results.detections[0]\n",
    "                box=detection.location_data.relative_bounding_box\n",
    "                x_min=int(box.xmin*w)\n",
    "                y_min=int(box.ymin*h)\n",
    "                x_max=x_min+int(box.width*w)\n",
    "                y_max=y_min+int(box.height*h)\n",
    "                fx1=max(0,x_min);fy1=max(0,y_min)\n",
    "                fx2=min(w,x_max);fy2=min(h,y_max)\n",
    "\n",
    "                face_roi=frame[fy1:fy2, fx1:fx2]\n",
    "                face_w=fx2-fx1\n",
    "                face_h=fy2-fy1\n",
    "                if face_roi.size>0:\n",
    "                    face_640=cv2.resize(face_roi,(640,640))\n",
    "                    results_gafas_masc=self.yolo_model.predict(face_640,imgsz=640,conf=0.25,verbose=False)\n",
    "                    for r in results_gafas_masc:\n",
    "                        for box_yolo in r.boxes:\n",
    "                            cls_id=int(box_yolo.cls[0])\n",
    "                            class_name=r.names[cls_id].lower()\n",
    "                            if class_name not in[\"glasses\",\"mask\"]:\n",
    "                                continue\n",
    "                            found_restriction=True\n",
    "                            x1_640,y1_640=int(box_yolo.xyxy[0][0]),int(box_yolo.xyxy[0][1])\n",
    "                            x2_640,y2_640=int(box_yolo.xyxy[0][2]),int(box_yolo.xyxy[0][3])\n",
    "                            s_x=face_w/640.0\n",
    "                            s_y=face_h/640.0\n",
    "                            bx1=fx1+int(x1_640*s_x)\n",
    "                            by1=fy1+int(y1_640*s_y)\n",
    "                            bx2=fx1+int(x2_640*s_x)\n",
    "                            by2=fy1+int(y2_640*s_y)\n",
    "                            color=(0,255,255) if class_name==\"glasses\" else (255,0,255)\n",
    "                            cv2.rectangle(frame,(bx1,by1),(bx2,by2),color,2)\n",
    "                            cv2.putText(\n",
    "                                frame,\n",
    "                                class_name,\n",
    "                                (bx2,by1),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                font_scale_cv,\n",
    "                                color,\n",
    "                                2\n",
    "                            )\n",
    "                            msg_login = \"Debe quitarse las gafas\" if class_name==\"glasses\" else \"Debe quitarse la mascarilla\"\n",
    "                            cv2.putText(\n",
    "                                frame,\n",
    "                                msg_login,\n",
    "                                (30,160),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                font_scale_cv,\n",
    "                                (0,0,255),\n",
    "                                2\n",
    "                            )\n",
    "\n",
    "        # Head pose\n",
    "        mesh_results_2=self.face_mesh.process(rgb_frame)\n",
    "        head_pose_text=\"Undefined\"\n",
    "        head_is_forward=False\n",
    "        color2 = (255,0,0)  ### CORREGIDO: Asignar por defecto\n",
    "\n",
    "        if mesh_results_2.multi_face_landmarks and len(mesh_results_2.multi_face_landmarks)==1:\n",
    "            face_landmarks=mesh_results_2.multi_face_landmarks[0]\n",
    "            face_3d=[]\n",
    "            face_2d=[]\n",
    "            for idx,lm in enumerate(face_landmarks.landmark):\n",
    "                if idx in [33,263,1,61,291,199]:\n",
    "                    xx,yy=int(lm.x*w),int(lm.y*h)\n",
    "                    face_2d.append([xx,yy])\n",
    "                    face_3d.append([xx,yy,lm.z])\n",
    "            if len(face_2d)==6:\n",
    "                focal_length=w\n",
    "                cam_matrix=np.array([[focal_length,0,h/2],\n",
    "                                     [0,focal_length,w/2],\n",
    "                                     [0,0,1]])\n",
    "                dist_matrix=np.zeros((4,1),dtype=np.float64)\n",
    "                ok_pnp, rot_vec, trans_vec=cv2.solvePnP(\n",
    "                    np.array(face_3d,dtype=np.float64),\n",
    "                    np.array(face_2d,dtype=np.float64),\n",
    "                    cam_matrix, dist_matrix\n",
    "                )\n",
    "                if ok_pnp:\n",
    "                    rmat,_=cv2.Rodrigues(rot_vec)\n",
    "                    angles,_,_,_,_,_=cv2.RQDecomp3x3(rmat)\n",
    "                    x_angle=angles[0]*360\n",
    "                    y_angle=angles[1]*360\n",
    "                    if y_angle< -4:\n",
    "                        head_pose_text=\"Mirando Izq.\"\n",
    "                    elif y_angle>5:\n",
    "                        head_pose_text=\"Mirando Der.\"\n",
    "                    elif x_angle< -3:\n",
    "                        head_pose_text=\"Mirando Abajo\"\n",
    "                    elif x_angle>8:\n",
    "                        head_pose_text=\"Mirando Arriba\"\n",
    "                    else:\n",
    "                        head_pose_text=\"Frente\"\n",
    "                        head_is_forward=True\n",
    "\n",
    "        # Elegir color\n",
    "        if head_is_forward:\n",
    "            color2=(0,255,0)\n",
    "        else:\n",
    "            color2=(255,0,0)\n",
    "\n",
    "        head_pose_text = \"Pos. Cabeza: \" + head_pose_text\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            head_pose_text,\n",
    "            (30,100),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale_cv,\n",
    "            color2,\n",
    "            2\n",
    "        )\n",
    "\n",
    "        if not head_is_forward:\n",
    "            found_restriction=True\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"La cabeza debe mirar al frente\",\n",
    "                (30,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.1,\n",
    "                (0,0,255),\n",
    "                2\n",
    "            )\n",
    "\n",
    "        if found_restriction:\n",
    "            self.blink_count=0\n",
    "            self.show_frame_on_label(frame)\n",
    "            self.video_label.after(10,self.update_frame_login)\n",
    "            return\n",
    "\n",
    "        # Revisar detección normal\n",
    "        if not detection_results.detections:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"No se detecta rostro\",\n",
    "                (30,90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale_cv,\n",
    "                (0,0,255),\n",
    "                2\n",
    "            )\n",
    "            self.show_frame_on_label(frame)\n",
    "            self.video_label.after(10,self.update_frame_login)\n",
    "            return\n",
    "\n",
    "        if len(detection_results.detections)>1:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"Debe haber 1 sola cara\",\n",
    "                (30,90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale_cv,\n",
    "                (0,0,255),\n",
    "                2\n",
    "            )\n",
    "            self.show_frame_on_label(frame)\n",
    "            self.video_label.after(10,self.update_frame_login)\n",
    "            return\n",
    "\n",
    "        detection=detection_results.detections[0]\n",
    "        if not mesh_results_2.multi_face_landmarks:\n",
    "            self.show_frame_on_label(frame)\n",
    "            self.video_label.after(10,self.update_frame_login)\n",
    "            return\n",
    "\n",
    "        face_landmarks_2=mesh_results_2.multi_face_landmarks[0]\n",
    "        landmarks=face_landmarks_2.landmark\n",
    "        left_eye_indices=[33,160,158,133,153,144]\n",
    "        right_eye_indices=[362,385,387,263,373,380]\n",
    "        left_eye_coords=[(int(landmarks[i].x*w),int(landmarks[i].y*h)) for i in left_eye_indices]\n",
    "        right_eye_coords=[(int(landmarks[i].x*w),int(landmarks[i].y*h)) for i in right_eye_indices]\n",
    "        left_EAR=self.calculate_EAR(left_eye_coords)\n",
    "        right_EAR=self.calculate_EAR(right_eye_coords)\n",
    "        ear_thr=0.2\n",
    "        eyes_open_now=(left_EAR>=ear_thr)and(right_EAR>=ear_thr)\n",
    "\n",
    "        if eyes_open_now:\n",
    "            if self.prev_eye_state==\"closed\" and not self.eye_transition_flag:\n",
    "                self.blink_count+=1\n",
    "                self.eye_transition_flag=True\n",
    "            self.prev_eye_state=\"open\"\n",
    "        else:\n",
    "            if self.prev_eye_state==\"open\":\n",
    "                self.eye_transition_flag=False\n",
    "            self.prev_eye_state=\"closed\"\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Pestaneos: {self.blink_count}\",\n",
    "            (30, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.3,\n",
    "            (0,255,0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "        if self.blink_count>=3:\n",
    "            mouth_top_idx=13\n",
    "            mouth_bottom_idx=14\n",
    "            mt=(int(landmarks[mouth_top_idx].x*w), int(landmarks[mouth_top_idx].y*h))\n",
    "            mb=(int(landmarks[mouth_bottom_idx].x*w), int(landmarks[mouth_bottom_idx].y*h))\n",
    "            mouth_dist=np.linalg.norm(np.array(mt)-np.array(mb))\n",
    "            mouth_closed=(mouth_dist<=30)\n",
    "            if eyes_open_now and mouth_closed:\n",
    "                # Evitar solapamiento de audio\n",
    "                if self.channel_instructions.get_busy():\n",
    "                    self.channel_instructions.stop()\n",
    "                if self.channel_errors.get_busy():\n",
    "                    self.channel_errors.stop()\n",
    "\n",
    "                face_crop=self.take_login_picture_rotated(clean_frame,detection)\n",
    "                if face_crop is None:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"No se pudo recortar la cara rotada\",\n",
    "                        (30,420),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.1,\n",
    "                        (0,0,255),\n",
    "                        2\n",
    "                    )\n",
    "                return\n",
    "            else:\n",
    "                faltan=[]\n",
    "                if not eyes_open_now:\n",
    "                    faltan.append(\"ojos abiertos\")\n",
    "                if not mouth_closed:\n",
    "                    faltan.append(\"boca cerrada\")\n",
    "                if faltan:\n",
    "                    msg_f=\"Condición faltante: \"+\", \".join(faltan)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        msg_f,\n",
    "                        (30,420),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.1,\n",
    "                        (0,0,255),\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "        self.show_frame_on_label(frame)\n",
    "        self.video_label.after(10,self.update_frame_login)\n",
    "\n",
    "    def take_login_picture_rotated(self,frame_bgr,detection):\n",
    "        \"\"\"Rota la imagen para alinear ojos y recorta la cara. Luego determina el usuario.\"\"\"\n",
    "        keypoints=detection.location_data.relative_keypoints\n",
    "        if len(keypoints)<2:\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            return None\n",
    "\n",
    "        hh, ww, _=frame_bgr.shape\n",
    "        right_eye_kp=keypoints[0]\n",
    "        left_eye_kp=keypoints[1]\n",
    "        rex=int(right_eye_kp.x*ww)\n",
    "        rey=int(right_eye_kp.y*hh)\n",
    "        lex=int(left_eye_kp.x*ww)\n",
    "        ley=int(left_eye_kp.y*hh)\n",
    "\n",
    "        dx=lex-rex\n",
    "        dy=ley-rey\n",
    "        angle=np.degrees(np.arctan2(dy,dx))\n",
    "\n",
    "        cx=(lex+rex)//2\n",
    "        cy=(ley+rey)//2\n",
    "        M=cv2.getRotationMatrix2D((cx,cy),angle,1.0)\n",
    "        rotated=cv2.warpAffine(frame_bgr,M,(ww,hh))\n",
    "\n",
    "        box=detection.location_data.relative_bounding_box\n",
    "        fxmin=int(box.xmin*ww);fymin=int(box.ymin*hh)\n",
    "        fw=int(box.width*ww);fh=int(box.height*hh)\n",
    "        fxmax=fxmin+fw\n",
    "        fymax=fymin+fh\n",
    "\n",
    "        corners=[(fxmin,fymin),(fxmax,fymin),(fxmin,fymax),(fxmax,fymax)]\n",
    "        rot_corners=[]\n",
    "        for(ccx,ccy)in corners:\n",
    "            new_xy=np.dot(M,np.array([ccx,ccy,1]))\n",
    "            rot_corners.append((int(new_xy[0]),int(new_xy[1])))\n",
    "\n",
    "        xs=[p[0] for p in rot_corners]\n",
    "        ys=[p[1] for p in rot_corners]\n",
    "        xmin_r,xmax_r=min(xs),max(xs)\n",
    "        ymin_r,ymax_r=min(ys),max(ys)\n",
    "\n",
    "        margin_x=int(0.10*fw)\n",
    "        margin_y=int(0.20*fh)\n",
    "\n",
    "        xmin_r=max(0,xmin_r-margin_x)\n",
    "        xmax_r=min(ww,xmax_r+margin_x)\n",
    "        ymin_r=max(0,ymin_r-margin_y)\n",
    "        ymax_r=min(hh,ymax_r+margin_y)\n",
    "\n",
    "        if xmin_r>=xmax_r or ymin_r>=ymax_r:\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            return None\n",
    "\n",
    "        face_unprocessed=rotated[ymin_r:ymax_r,xmin_r:xmax_r]\n",
    "        if face_unprocessed.size==0:\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            return None\n",
    "\n",
    "        face_processed=enhance_image_cv2(face_unprocessed)\n",
    "        self.login_image_pil_unprocessed=Image.fromarray(cv2.cvtColor(face_unprocessed,cv2.COLOR_BGR2RGB))\n",
    "        self.login_image_pil=Image.fromarray(cv2.cvtColor(face_processed,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        temp_path=\"login_temp.png\"\n",
    "        self.login_image_pil.save(temp_path)\n",
    "\n",
    "        emb_data=DeepFace.represent(img_path=temp_path,model_name=\"Facenet\",enforce_detection=False)\n",
    "        if(len(emb_data)==0)or(\"embedding\"not in emb_data[0]):\n",
    "            messagebox.showerror(\"Error\",\"No se pudo generar embedding.\")\n",
    "            self.current_logged_in_user=\"Desconocido\"\n",
    "            self.login_embedding_vector=None\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            if os.path.exists(temp_path): os.remove(temp_path)\n",
    "            return None\n",
    "\n",
    "        arr=np.array(emb_data[0][\"embedding\"]).flatten()\n",
    "        if arr.shape[0]!=128:\n",
    "            messagebox.showerror(\"Error\",\"Embedding inválido (no 128).\")\n",
    "            self.current_logged_in_user=\"Desconocido\"\n",
    "            self.login_embedding_vector=None\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            if os.path.exists(temp_path):os.remove(temp_path)\n",
    "            return None\n",
    "\n",
    "        user_dirs=[d for d in os.listdir(\"usuarios/\") if os.path.isdir(os.path.join(\"usuarios/\", d))]\n",
    "        if not user_dirs:\n",
    "            messagebox.showinfo(\"Login\",\"No hay usuarios registrados. Serás 'Desconocido'.\")\n",
    "            self.current_logged_in_user=\"Desconocido\"\n",
    "            self.login_embedding_vector=arr\n",
    "            self.finish_login_process(open_profile=True)\n",
    "            if os.path.exists(temp_path):os.remove(temp_path)\n",
    "            return face_unprocessed\n",
    "\n",
    "        threshold=0.25\n",
    "        best_distance=float('inf')\n",
    "        best_user=None\n",
    "\n",
    "        for user_dir in user_dirs:\n",
    "            emb_json_path=os.path.join(\"usuarios\",user_dir,\"embeddings.json\")\n",
    "            if not os.path.exists(emb_json_path): \n",
    "                continue\n",
    "            with open(emb_json_path,\"r\")as f:\n",
    "                data=json.load(f)\n",
    "            un=data[\"username\"]\n",
    "            user_embs=data[\"embeddings\"]\n",
    "            for emb_vector in user_embs:\n",
    "                user_arr=np.array(emb_vector).flatten()\n",
    "                if user_arr.shape[0]!=128: \n",
    "                    continue\n",
    "                dist=df_verification.find_cosine_distance(arr,user_arr)\n",
    "                if dist<best_distance:\n",
    "                    best_distance=dist\n",
    "                    best_user=un\n",
    "\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "        if (best_user is not None)and(best_distance<threshold):\n",
    "            messagebox.showinfo(\"Login\",f\"¡Bienvenido, {best_user}!\")\n",
    "            self.current_logged_in_user=best_user\n",
    "            self.login_embedding_vector=arr\n",
    "        else:\n",
    "            messagebox.showinfo(\"Login\",\"No se encontró coincidencia. Serás 'Desconocido'.\")\n",
    "            self.current_logged_in_user=\"Desconocido\"\n",
    "            self.login_embedding_vector=arr\n",
    "\n",
    "        self.finish_login_process(open_profile=True)\n",
    "        return face_unprocessed\n",
    "\n",
    "    def finish_login_process(self, open_profile=False):\n",
    "        \"\"\"Finaliza el proceso de Login y pasa a la pantalla de perfil si open_profile=True.\"\"\"\n",
    "        self.is_logging_in=False\n",
    "        self.video_label.place_forget()\n",
    "\n",
    "        ### NUEVO: Registrar en el log la sesión\n",
    "        self.log_user_login(self.current_logged_in_user)\n",
    "\n",
    "        if open_profile:\n",
    "            self.show_profile_frame()\n",
    "        else:\n",
    "            self.return_to_start()\n",
    "\n",
    "    ### NUEVO: Función para escribir el log de inicios de sesión\n",
    "    def log_user_login(self, username):\n",
    "        \"\"\"\n",
    "        Inserta una línea al comienzo del archivo 'login_history.log' \n",
    "        con:  <usuario>,<fecha-hora>\\n\n",
    "        \"\"\"\n",
    "        log_file = \"login_history.log\"\n",
    "        now_str = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        new_line = f\"{username},{now_str}\\n\"\n",
    "        lines = []\n",
    "        if os.path.exists(log_file):\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "        # Insertar al inicio\n",
    "        lines.insert(0, new_line)\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(lines)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # PERFIL\n",
    "    # ---------------------------------------------------------------\n",
    "    def show_profile_frame(self):\n",
    "        self.login_frame.place_forget()\n",
    "        self.profile_frame.place(x=0,y=0,width=800,height=600)\n",
    "        self.setup_profile_frame()\n",
    "\n",
    "    def setup_profile_frame(self):\n",
    "        \"\"\"Construye la pantalla de perfil.\"\"\"\n",
    "        for w in self.profile_frame.winfo_children():\n",
    "            w.destroy()\n",
    "\n",
    "        frame_title=tk.Frame(self.profile_frame,bg=\"#444444\")\n",
    "        frame_title.pack(fill=\"x\")\n",
    "\n",
    "        user_label_text=f\"Perfil de {self.current_logged_in_user}\"\n",
    "        lbl_title=tk.Label(frame_title,text=user_label_text,font=(\"Helvetica\",18,\"bold\"),\n",
    "                           bg=\"#444444\",fg=\"#ffffff\")\n",
    "        lbl_title.pack(anchor=\"center\",pady=10)\n",
    "\n",
    "        frame_main=tk.Frame(self.profile_frame,bg=\"#2c2c2c\")\n",
    "        frame_main.pack(fill=\"both\",expand=True)\n",
    "\n",
    "        frame_left=tk.Frame(frame_main,bg=\"#333333\")\n",
    "        frame_left.pack(side=\"left\",fill=\"y\",padx=20,pady=20)\n",
    "\n",
    "        frame_center=tk.Frame(frame_main,bg=\"#2c2c2c\")\n",
    "        frame_center.pack(side=\"left\",fill=\"both\",expand=True,pady=20)\n",
    "\n",
    "        frame_img=tk.LabelFrame(frame_center,text=\"Comparación\",\n",
    "                                fg=\"#ffffff\",bg=\"#2c2c2c\",labelanchor=\"n\",\n",
    "                                font=(\"Helvetica\",12,\"bold\"),bd=2)\n",
    "        frame_img.pack(side=\"top\",padx=20,pady=10)\n",
    "\n",
    "        frm_two=tk.Frame(frame_img,bg=\"#2c2c2c\")\n",
    "        frm_two.pack()\n",
    "\n",
    "        if self.login_image_pil and self.login_image_pil_unprocessed:\n",
    "            img_tk_proc=ImageTk.PhotoImage(self.login_image_pil)\n",
    "            lbl_image_proc=tk.Label(frm_two,image=img_tk_proc,bg=\"#2c2c2c\")\n",
    "            lbl_image_proc.image=img_tk_proc\n",
    "            lbl_image_proc.pack(side=\"left\",padx=10,pady=10)\n",
    "\n",
    "            img_tk_unproc=ImageTk.PhotoImage(self.login_image_pil_unprocessed)\n",
    "            lbl_image_unproc=tk.Label(frm_two,image=img_tk_unproc,bg=\"#2c2c2c\")\n",
    "            lbl_image_unproc.image=img_tk_unproc\n",
    "            lbl_image_unproc.pack(side=\"right\",padx=10,pady=10)\n",
    "        else:\n",
    "            lbl_no_img=tk.Label(frame_img,text=\"(No hay imagen de login)\",\n",
    "                                font=(\"Helvetica\",12),bg=\"#2c2c2c\",fg=\"#ffffff\")\n",
    "            lbl_no_img.pack(padx=10,pady=10)\n",
    "\n",
    "        self.predictions_label=tk.Label(frame_center,\n",
    "                                        textvariable=self.predictions_label_var,\n",
    "                                        font=(\"Helvetica\",12),\n",
    "                                        fg=\"#00FF00\",bg=\"#2c2c2c\",justify=\"left\")\n",
    "        self.predictions_label.pack(side=\"top\",padx=10,pady=10)\n",
    "\n",
    "        btn_stats=tk.Button(frame_left,text=\"Ver Estadísticas\",\n",
    "                            font=(\"Helvetica\",12,\"bold\"),bg=\"#00aaff\",fg=\"#ffffff\",\n",
    "                            padx=10,pady=5,command=self.show_stats_frame)\n",
    "        btn_stats.pack(pady=5,fill=\"x\")\n",
    "\n",
    "        btn_symmetry=tk.Button(frame_left,text=\"Evaluar Simetría\",\n",
    "                               font=(\"Helvetica\",12,\"bold\"),bg=\"#00aaff\",fg=\"#ffffff\",\n",
    "                               padx=10,pady=5,command=self.evaluate_facial_symmetry_window)\n",
    "        btn_symmetry.pack(pady=5,fill=\"x\")\n",
    "\n",
    "        btn_preds=tk.Button(frame_left,text=\"Predicciones\",\n",
    "                            font=(\"Helvetica\",12,\"bold\"),bg=\"#00aaff\",fg=\"#ffffff\",\n",
    "                            padx=10,pady=5,command=self.show_predictions)\n",
    "        btn_preds.pack(pady=5,fill=\"x\")\n",
    "\n",
    "        lbl_sym=tk.Label(frame_left,textvariable=self.simmetry_label_var,\n",
    "                         font=(\"Helvetica\",12,\"bold\"),bg=\"#333333\",fg=\"#ffffff\")\n",
    "        lbl_sym.pack(pady=10,fill=\"x\")\n",
    "\n",
    "        # NUEVO: Botón \"Cuenta\"/\"Datos\"\n",
    "        if self.current_logged_in_user and self.current_logged_in_user != \"Desconocido\":\n",
    "            btn_account = tk.Button(\n",
    "                frame_left, \n",
    "                text=\"Cuenta\", \n",
    "                font=(\"Helvetica\",12,\"bold\"),\n",
    "                bg=\"#90ee90\", \n",
    "                fg=\"#000000\", \n",
    "                padx=10, \n",
    "                pady=5,\n",
    "                command=self.show_account_info\n",
    "            )\n",
    "            btn_account.pack(pady=5,fill=\"x\")\n",
    "\n",
    "        if self.current_logged_in_user==\"Desconocido\":\n",
    "            btn_registrar=tk.Button(frame_left,text=\"Registrar\",\n",
    "                                    font=(\"Helvetica\",12,\"bold\"),bg=\"#ffa500\",fg=\"#ffffff\",\n",
    "                                    padx=10,pady=5,command=self.go_to_signup)\n",
    "            btn_registrar.pack(pady=5,fill=\"x\")\n",
    "\n",
    "        btn_volver=tk.Button(frame_left,text=\"Volver\",\n",
    "                             font=(\"Helvetica\",12,\"bold\"),bg=\"#ff6666\",fg=\"#ffffff\",\n",
    "                             padx=10,pady=5,command=self.return_to_start)\n",
    "        btn_volver.pack(side=\"bottom\",pady=20,fill=\"x\")\n",
    "\n",
    "    ### NUEVO: Mostrar datos de la cuenta desde el log\n",
    "    def show_account_info(self):\n",
    "        \"\"\"\n",
    "        Lee el archivo 'login_history.log' y muestra:\n",
    "         - Número de veces que ha iniciado sesión el usuario actual.\n",
    "         - Fecha/hora de la última conexión (la más reciente en el log).\n",
    "        \"\"\"\n",
    "        if (not self.current_logged_in_user) or (self.current_logged_in_user == \"Desconocido\"):\n",
    "            messagebox.showinfo(\"Cuenta\", \"No hay datos para 'Desconocido'.\")\n",
    "            return\n",
    "\n",
    "        log_file = \"login_history.log\"\n",
    "        if not os.path.exists(log_file):\n",
    "            messagebox.showinfo(\"Cuenta\", \"No hay historial de inicio de sesión aún.\")\n",
    "            return\n",
    "\n",
    "        with open(log_file, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Filtrar líneas que empiecen con \"<username>,\"\n",
    "        user_lines = [line.strip() for line in lines if line.startswith(f\"{self.current_logged_in_user},\")]\n",
    "        times_logged_in = len(user_lines)\n",
    "\n",
    "        #No deberia de suceder, pero...\n",
    "        if times_logged_in == 0:\n",
    "            messagebox.showinfo(\"Cuenta\", \"No se ha registrado inicio de sesión para este usuario.\")\n",
    "            return\n",
    "        # Verificar si hay más de una línea para identificar la última conexión previa\n",
    "        if times_logged_in > 1:\n",
    "            last_connection = user_lines[1]  # Segunda línea es la conexión previa más reciente\n",
    "            parts_last_connection = last_connection.split(',')\n",
    "            date_time_last_connection = parts_last_connection[1] if len(parts_last_connection) > 1 else \"desconocido\"\n",
    "        else:\n",
    "            date_time_last_connection = \"No existente\"  # No hay conexión previa registrada\n",
    "\n",
    "        info_msg = (\n",
    "            f\"Has iniciado sesión {times_logged_in} veces.\\n\"\n",
    "            f\"Última conexión: {date_time_last_connection}\"\n",
    "        )\n",
    "        messagebox.showinfo(\"Cuenta\", info_msg)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Funciones de Perfil, Stats, etc.\n",
    "    # ---------------------------------------------------------------\n",
    "    def evaluate_facial_symmetry_window(self):\n",
    "        # 1. Verificar que tengas la imagen de login\n",
    "        if self.login_image_pil is None:\n",
    "            messagebox.showinfo(\"Simetría\",\"No hay imagen de login procesada.\")\n",
    "            return\n",
    "\n",
    "        # 2. Convertir a BGR para procesar con Mediapipe\n",
    "        face_bgr = cv2.cvtColor(np.array(self.login_image_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 3. Correr FaceMesh sobre esa imagen\n",
    "        mp_mesh = mp.solutions.face_mesh\n",
    "        with mp_mesh.FaceMesh(\n",
    "            static_image_mode=True, \n",
    "            max_num_faces=1,\n",
    "            min_detection_confidence=0.5\n",
    "        ) as face_mesh:\n",
    "            results = face_mesh.process(cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # 4. Si no hay landmarks, avisa\n",
    "        if not results.multi_face_landmarks:\n",
    "            messagebox.showinfo(\"Simetría\",\"No se detectó la malla de la cara.\")\n",
    "            return\n",
    "\n",
    "        # 5. Tomar la malla (un solo rostro)\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        h, w, _ = face_bgr.shape\n",
    "\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for lm in face_landmarks.landmark:\n",
    "            xs.append(int(lm.x * w))\n",
    "            ys.append(int(lm.y * h))\n",
    "        \n",
    "        x_left   = min(xs)\n",
    "        x_right  = max(xs)\n",
    "        y_top    = min(ys)\n",
    "        y_bottom = max(ys)\n",
    "\n",
    "        # 6. Recortar la cara en base al Mesh\n",
    "        # Asegúrate de no salirte de los límites\n",
    "        x_left = max(0, x_left)\n",
    "        x_right = min(w, x_right)\n",
    "        y_top = max(0, y_top)\n",
    "        y_bottom = min(h, y_bottom)\n",
    "\n",
    "        if x_left >= x_right or y_top >= y_bottom:\n",
    "            messagebox.showinfo(\"Simetría\",\"La región del mesh es inválida.\")\n",
    "            return\n",
    "\n",
    "        face_roi = face_bgr[y_top : y_bottom, x_left : x_right]\n",
    "        hh, ww, _ = face_roi.shape\n",
    "\n",
    "        # 7. Dividir la cara en dos mitades verticales\n",
    "        # y hacer el cálculo de MSE (o la métrica que tengas).\n",
    "        # Asegúrate de que la anchura sea par:\n",
    "        if ww % 2 != 0:\n",
    "            ww -= 1\n",
    "            face_roi = face_roi[:, :ww]  # recorta 1 píxel a la derecha\n",
    "\n",
    "        mid_x = ww // 2\n",
    "\n",
    "        left_half = face_roi[:, :mid_x]\n",
    "        right_half = face_roi[:, mid_x:]\n",
    "\n",
    "        # 8. Reflejar la mitad derecha\n",
    "        right_half_flipped = cv2.flip(right_half, 1)\n",
    "\n",
    "        # 8.1 Guardar las imágenes de la mitad izquierda y derecha reflejada en disco.\n",
    "        #cv2.imwrite(\"left_half.jpg\", left_half)\n",
    "        #cv2.imwrite(\"right_half_flipped.jpg\", right_half_flipped)\n",
    "\n",
    "        # 9. Calcular MSE entre left_half y right_half_flipped\n",
    "        arr_left = left_half.astype(np.float32)\n",
    "        arr_right = right_half_flipped.astype(np.float32)\n",
    "        mse = np.mean((arr_left - arr_right) ** 2)\n",
    "\n",
    "        # 10. Escalar / interpretar la MSE como porcentaje de simetría\n",
    "        max_mse = 5000.0\n",
    "        simmetry_percent = max(0, 100 * (1 - (mse / max_mse)))\n",
    "        if simmetry_percent > 100:\n",
    "            simmetry_percent = 100\n",
    "\n",
    "        # 11. Mostrar resultado\n",
    "        self.simmetry_label_var.set(f\"Simetría: {simmetry_percent:.1f}%\")\n",
    "\n",
    "        # Dibuja líneas, etc. en la ROI para visual:\n",
    "        col_line = (0,255,255)\n",
    "        for y_ in range(0, hh, 10):\n",
    "            cv2.line(face_roi, (mid_x, y_), (mid_x, y_+5), col_line, 1)\n",
    "\n",
    "        cv2.rectangle(face_roi, (0, 0), (ww-1, hh-1), (0,255,0), 2)\n",
    "        cv2.putText(face_roi, f\"{simmetry_percent:.1f}%\", (10,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "        # 12. Mostrar en un popup (por ejemplo)\n",
    "        show_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(show_rgb)\n",
    "\n",
    "        win_sym = tk.Toplevel(self)\n",
    "        win_sym.title(\"Resultado Simetría Facial (Mesh)\")\n",
    "\n",
    "        sym_label = tk.Label(win_sym)\n",
    "        sym_label.pack()\n",
    "\n",
    "        imgtk = ImageTk.PhotoImage(pil_img)\n",
    "        sym_label.imgtk = imgtk\n",
    "        sym_label.configure(image=imgtk)\n",
    "\n",
    "        btn_close = tk.Button(win_sym, text=\"Cerrar\", font=(\"Helvetica\",12),\n",
    "                            bg=\"#ff6666\", fg=\"#ffffff\",\n",
    "                            command=win_sym.destroy)\n",
    "        btn_close.pack(pady=5)\n",
    "\n",
    "    def show_predictions(self):\n",
    "        \"\"\"\n",
    "            Se analiza con deepfaec edad, género, raza y emocion y se traduce mediante uso de diccionarios los resultados\n",
    "        \"\"\"\n",
    "        if not self.login_image_pil_unprocessed:\n",
    "            messagebox.showinfo(\"Predicciones\",\"No hay imagen de login sin procesar.\")\n",
    "            return\n",
    "\n",
    "        face_bgr=cv2.cvtColor(np.array(self.login_image_pil_unprocessed),cv2.COLOR_RGB2BGR)\n",
    "        face_rgb=cv2.cvtColor(face_bgr,cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            analysis=DeepFace.analyze(img_path=face_rgb,\n",
    "                                      actions=['age','gender','race','emotion'],\n",
    "                                      enforce_detection=False)\n",
    "            age=analysis[0]['age']\n",
    "            gender=analysis[0]['gender']\n",
    "            race_en=analysis[0]['dominant_race']\n",
    "            emo_en=analysis[0]['dominant_emotion']\n",
    "\n",
    "            gender_info=analysis[0].get(\"gender\",{})\n",
    "            if isinstance(gender_info,dict):\n",
    "                man_score=gender_info.get(\"Man\",0.0)\n",
    "                woman_score=gender_info.get(\"Woman\",0.0)\n",
    "                if man_score>woman_score:\n",
    "                    gender_en=\"Man\"\n",
    "                    gender_conf=man_score\n",
    "                else:\n",
    "                    gender_en=\"Woman\"\n",
    "                    gender_conf=woman_score\n",
    "            else:\n",
    "                gender_en=\"Man\" if gender==\"Man\" else \"Woman\"\n",
    "                gender_conf=1.0\n",
    "\n",
    "            dict_gender={\"Man\":\"Hombre\",\"Woman\":\"Mujer\"}\n",
    "            gender_es=dict_gender.get(gender_en,\"Desconocido\")\n",
    "            conf_str=f\"{gender_conf:.3f}\"\n",
    "\n",
    "            dict_race={\n",
    "                \"asian\":\"Asiático\",\"white\":\"Blanco\",\n",
    "                \"middle eastern\":\"Medio Oriente\",\"indian\":\"Indio\",\n",
    "                \"latino hispanic\":\"Latino\",\"black\":\"Negro\"\n",
    "            }\n",
    "            race_en_lower=race_en.lower() if isinstance(race_en,str) else\"\"\n",
    "            race_es=dict_race.get(race_en_lower,race_en)\n",
    "\n",
    "            dict_emotion={\n",
    "                \"angry\":\"Enojado\",\"fear\":\"Miedo\",\"neutral\":\"Neutral\",\n",
    "                \"sad\":\"Triste\",\"disgust\":\"Asco\",\"happy\":\"Feliz\",\"surprise\":\"Sorpresa\"\n",
    "            }\n",
    "            emo_en_lower=emo_en.lower() if isinstance(emo_en,str) else\"\"\n",
    "            emo_es=dict_emotion.get(emo_en_lower,emo_en)\n",
    "\n",
    "            msg=(f\"Edad: {age}\\n\"\n",
    "                 f\"Género: {gender_es} (conf: {conf_str})\\n\"\n",
    "                 f\"Raza dominante: {race_es}\\n\"\n",
    "                 f\"Emoción dominante: {emo_es}\")\n",
    "            self.predictions_label_var.set(msg)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\",f\"No se pudo analizar: {str(e)}\")\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Stats\n",
    "    # ---------------------------------------------------------------\n",
    "    def show_stats_frame(self):\n",
    "        \"\"\"Muestra pantalla de similitud (stats).\"\"\"\n",
    "        self.profile_frame.place_forget()\n",
    "        self.stats_frame.place(x=0,y=0,width=800,height=600)\n",
    "        self.setup_stats_frame()\n",
    "\n",
    "    def setup_stats_frame(self):\n",
    "        for w in self.stats_frame.winfo_children():\n",
    "            w.destroy()\n",
    "\n",
    "        lbl_title=tk.Label(self.stats_frame,\n",
    "                           text=\"Similitud respecto a cada usuario (tabla)\",\n",
    "                           font=(\"Helvetica\",14,\"bold\"),bg=\"#3e3e3e\",fg=\"#ffffff\")\n",
    "        lbl_title.pack(pady=10)\n",
    "\n",
    "        lbl_header=tk.Label(self.stats_frame,\n",
    "            text=\"Nombre             Coseno        Euclidea        Manhattan\",\n",
    "            font=(\"Courier\",12,\"bold\"),bg=\"#3e3e3e\",fg=\"#ffffff\"\n",
    "        )\n",
    "        lbl_header.pack(pady=5)\n",
    "\n",
    "        if self.login_embedding_vector is None:\n",
    "            lbl_none=tk.Label(self.stats_frame,\n",
    "                              text=\"No hay embedding para calcular similitudes\",\n",
    "                              font=(\"Helvetica\",12),bg=\"#3e3e3e\",fg=\"#ffffff\")\n",
    "            lbl_none.pack(pady=10)\n",
    "        else:\n",
    "            user_dirs=[d for d in os.listdir(\"usuarios/\") if os.path.isdir(os.path.join(\"usuarios/\",d))]\n",
    "            if not user_dirs:\n",
    "                lbl_no_users=tk.Label(self.stats_frame,\n",
    "                                      text=\"No hay usuarios registrados\",\n",
    "                                      font=(\"Helvetica\",12),bg=\"#3e3e3e\",fg=\"#ffffff\")\n",
    "                lbl_no_users.pack(pady=10)\n",
    "            else:\n",
    "                for user_dir in user_dirs:\n",
    "                    emb_json_path=os.path.join(\"usuarios\",user_dir,\"embeddings.json\")\n",
    "                    if not os.path.exists(emb_json_path):\n",
    "                        continue\n",
    "                    with open(emb_json_path,\"r\") as f:\n",
    "                        data=json.load(f)\n",
    "                    user_name_in_json=data[\"username\"]\n",
    "                    user_embeddings=data[\"embeddings\"]\n",
    "\n",
    "                    best_cos_dist=float('inf')\n",
    "                    best_euc_dist=float('inf')\n",
    "                    best_man_dist=float('inf')\n",
    "\n",
    "                    for emb_vector in user_embeddings:\n",
    "                        user_arr=np.array(emb_vector).flatten()\n",
    "                        if user_arr.shape[0]!=128: \n",
    "                            continue\n",
    "\n",
    "                        dist_cos=df_verification.find_cosine_distance(\n",
    "                            self.login_embedding_vector,user_arr)\n",
    "                        dist_euc=euclidean_distance(self.login_embedding_vector,user_arr)\n",
    "                        dist_man=manhattan_distance(self.login_embedding_vector,user_arr)\n",
    "\n",
    "                        if dist_cos<best_cos_dist:\n",
    "                            best_cos_dist=dist_cos\n",
    "                        if dist_euc<best_euc_dist:\n",
    "                            best_euc_dist=dist_euc\n",
    "                        if dist_man<best_man_dist:\n",
    "                            best_man_dist=dist_man\n",
    "\n",
    "                    # \"Similitud\" estilo \"porcentaje\"\n",
    "                    cos_sim=(1 - best_cos_dist)*100\n",
    "                    euc_sim=max(0,100-(best_euc_dist*2.5))\n",
    "                    man_sim=max(0,100-(best_man_dist*0.5))\n",
    "\n",
    "                    cos_sim=min(100,max(0,cos_sim))\n",
    "                    euc_sim=min(100,euc_sim)\n",
    "                    man_sim=min(100,man_sim)\n",
    "\n",
    "                    row_text=f\"{user_name_in_json:<20}{cos_sim:>6.1f}%{euc_sim:>14.1f}%{man_sim:>14.1f}%\"\n",
    "\n",
    "                    if user_name_in_json==self.current_logged_in_user:\n",
    "                        lbl_user_stat=tk.Label(\n",
    "                            self.stats_frame,text=row_text,font=(\"Courier\",12),\n",
    "                            bg=\"#aaaaaa\",\n",
    "                            fg=\"#000000\"\n",
    "                        )\n",
    "                    else:\n",
    "                        lbl_user_stat=tk.Label(\n",
    "                            self.stats_frame,text=row_text,font=(\"Courier\",12),\n",
    "                            bg=\"#3e3e3e\",fg=\"#ffffff\"\n",
    "                        )\n",
    "                    lbl_user_stat.pack(pady=2)\n",
    "\n",
    "        btn_volver_stats=tk.Button(self.stats_frame,text=\"Volver\",font=(\"Helvetica\",12),\n",
    "                                   bg=\"#ff6666\",fg=\"#ffffff\",command=self.return_to_profile)\n",
    "        btn_volver_stats.pack(pady=20)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Utilidades\n",
    "    # ---------------------------------------------------------------\n",
    "    def show_frame_on_label(self, frame_bgr):\n",
    "        rgb_frame=cv2.cvtColor(frame_bgr,cv2.COLOR_BGR2RGB)\n",
    "        imgtk=ImageTk.PhotoImage(Image.fromarray(rgb_frame))\n",
    "        self.video_label.imgtk=imgtk\n",
    "        self.video_label.configure(image=imgtk)\n",
    "\n",
    "    def resize_for_label(self, frame, desired_size):\n",
    "        target_w, target_h=desired_size\n",
    "        h,w,_=frame.shape\n",
    "        aspect_original=w/h\n",
    "        aspect_target=target_w/target_h\n",
    "\n",
    "        if aspect_original>aspect_target:\n",
    "            new_w=int(aspect_target*h)\n",
    "            x0=(w-new_w)//2\n",
    "            frame=frame[:, x0:x0+new_w]\n",
    "            frame=cv2.resize(frame,(target_w,target_h))\n",
    "        else:\n",
    "            new_h=int(w/aspect_target)\n",
    "            y0=(h-new_h)//2\n",
    "            frame=frame[y0:y0+new_h, :]\n",
    "            frame=cv2.resize(frame,(target_w,target_h))\n",
    "        return frame\n",
    "\n",
    "    def return_to_start(self):\n",
    "        self.blink_count=0\n",
    "        self.signup_frame.place_forget()\n",
    "        self.login_frame.place_forget()\n",
    "        self.profile_frame.place_forget()\n",
    "        self.stats_frame.place_forget()\n",
    "        self.video_label.place_forget()\n",
    "        self.start_frame.place(x=0,y=0,width=800,height=600)\n",
    "        self.simmetry_label_var = tk.StringVar(value=\"\")\n",
    "        self.predictions_label_var = tk.StringVar(value=\"\")\n",
    "\n",
    "\n",
    "    def return_to_profile(self):\n",
    "        self.stats_frame.place_forget()\n",
    "        self.show_profile_frame()\n",
    "\n",
    "    def calculate_EAR(self, eye_points):\n",
    "        if len(eye_points)<6:\n",
    "            return 0\n",
    "        A=np.linalg.norm(np.array(eye_points[1])-np.array(eye_points[5]))\n",
    "        B=np.linalg.norm(np.array(eye_points[2])-np.array(eye_points[4]))\n",
    "        C=np.linalg.norm(np.array(eye_points[0])-np.array(eye_points[3]))\n",
    "        EAR=(A+B)/(2.0*C) if C!=0 else 0\n",
    "        return EAR\n",
    "\n",
    "    def handle_error_sounds(self, eyes_open, mouth_closed):\n",
    "        \"\"\"Reproduce audio de error si ojos cerrados/boca abierta y respeta cooldown.\"\"\"\n",
    "        now=time.time()\n",
    "        if self.channel_instructions.get_busy() or self.channel_errors.get_busy():\n",
    "            return\n",
    "\n",
    "        if not eyes_open:\n",
    "            if (now-self.ultimo_sonido_ojos)>=self.audio_cooldown:\n",
    "                self.pause_background_music()\n",
    "                self.channel_errors.play(self.audio_ojos)\n",
    "                dur_ojos=self.audio_ojos.get_length()\n",
    "                self.after(int(dur_ojos*1000),self.resume_background_music)\n",
    "                self.ultimo_sonido_ojos=now\n",
    "            return\n",
    "\n",
    "        if not mouth_closed:\n",
    "            if (now-self.ultimo_sonido_boca)>=self.audio_cooldown:\n",
    "                self.pause_background_music()\n",
    "                self.channel_errors.play(self.audio_boca)\n",
    "                dur_boca=self.audio_boca.get_length()\n",
    "                self.after(int(dur_boca*1000),self.resume_background_music)\n",
    "                self.ultimo_sonido_boca=now\n",
    "\n",
    "    def show_flash_effect(self):\n",
    "        self.flash_label.place(x=0,y=0,width=800,height=600)\n",
    "        self.after(200,self.flash_label.place_forget)\n",
    "\n",
    "    def define_ellipse_for_current_offset(self, face_box, frame_size):\n",
    "        \"\"\"Posicionamiento y tamaño de óvalos\"\"\"\n",
    "        x_min, y_min, x_max, y_max = face_box\n",
    "        w, h = frame_size\n",
    "        face_cx = (x_min + x_max) // 2\n",
    "        face_cy = (y_min + y_max) // 2\n",
    "\n",
    "        rx = int((w/3)/1.8)\n",
    "        ry = int((h/2)/1.8)\n",
    "\n",
    "        offset_x, offset_y = self.ellipse_offsets[self.current_ellipse_index]\n",
    "\n",
    "        cx = face_cx + offset_x\n",
    "        cy = face_cy + offset_y\n",
    "\n",
    "        # Asegura que \"cy\" no pase de la mitad de la pantalla:\n",
    "        cy = min(cy, h // 2)\n",
    "\n",
    "        # Ajustar para no salirse de la pantalla\n",
    "        if cx - rx < 0: \n",
    "            cx = rx\n",
    "        if cx + rx > w: \n",
    "            cx = w - rx\n",
    "        if cy - ry < 0: \n",
    "            cy = ry\n",
    "        # aunque definiste cy = min(cy, h//2), podrías dejarle un margen\n",
    "        if cy + ry > h: \n",
    "            cy = h - ry\n",
    "\n",
    "        self.current_ellipse = (cx, cy, rx, ry)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Funciones Antiguas utilizadas como pruebas a la hora de trabajar con MediaPipe y el ovalo. \n",
    "\n",
    "    Función para ver si el centro de la bounding box de la cara está en el ovalo:\n",
    "    def is_face_inside_ellipse_by_center(self, face_box, cx, cy, rx, ry):\n",
    "        x_min, y_min, x_max, y_max = face_box\n",
    "        face_cx = (x_min + x_max) // 2\n",
    "        face_cy = (y_min + y_max) // 2\n",
    "        return self.is_point_in_rotated_ellipse(face_cx, face_cy, cx, cy, rx, ry, 0)\n",
    "\n",
    "\n",
    "    Comprueba que las 4 esquinas de la bounding box esten dentro:\n",
    "    def is_face_inside_rotated_ellipse(self, face_box, cx, cy, rx, ry, angle):\n",
    "        x_min,y_min,x_max,y_max = face_box\n",
    "        corners=[(x_min,y_min),(x_max,y_min),(x_min,y_max),(x_max,y_max)]\n",
    "        inside_count=0\n",
    "        for(xx,yy)in corners:\n",
    "            if self.is_point_in_rotated_ellipse(xx,yy,cx,cy,rx,ry,angle):\n",
    "                inside_count+=1\n",
    "        return (inside_count==4)\n",
    "\n",
    "    \"\"\"\n",
    "    def is_face_inside_rotated_ellipse_mesh(self, mesh_points, cx, cy, rx, ry, angle):\n",
    "        \"\"\"\n",
    "        Se comprueba que se encuentre la face mesh dentro del ovalo\n",
    "        \"\"\"\n",
    "        # mesh_points son 4 tuplas (x,y)\n",
    "        inside_count = 0\n",
    "        for (xx, yy) in mesh_points:\n",
    "            if self.is_point_in_rotated_ellipse(xx, yy, cx, cy, rx, ry, angle):\n",
    "                inside_count += 1\n",
    "        # Deben estar dentro los 4 puntos\n",
    "        return (inside_count == 4) \n",
    "\n",
    "    def is_face_inside_rotated_ellipse(self,face_box,cx,cy,rx,ry,angle):\n",
    "        x_min,y_min,x_max,y_max=face_box\n",
    "        corners=[(x_min,y_min),(x_max,y_min),(x_min,y_max),(x_max,y_max)]\n",
    "        inside_count=0\n",
    "        for(xx,yy)in corners:\n",
    "            if self.is_point_in_rotated_ellipse(xx,yy,cx,cy,rx,ry,angle):\n",
    "                inside_count+=1\n",
    "        return (inside_count==3)    \n",
    "\n",
    "    def is_point_in_rotated_ellipse(self,x,y,cx,cy,rx,ry,angle):\n",
    "        xx=x-cx\n",
    "        yy=y-cy\n",
    "        import math\n",
    "        theta=math.radians(-angle)\n",
    "        cos_t=math.cos(theta)\n",
    "        sin_t=math.sin(theta)\n",
    "        x_rot=xx*cos_t - yy*sin_t\n",
    "        y_rot=xx*sin_t + yy*cos_t\n",
    "        val=(x_rot**2)/(rx**2)+(y_rot**2)/(ry**2)\n",
    "        return (val<=1.0)\n",
    "\n",
    "#--------------------Sección 4: Ejecución de la Aplicación-------------------------------\n",
    "\"\"\"\n",
    "Finalmente, se instancia la clase principal `App` y se inicia el loop principal \n",
    "de la interfaz de usuario (`mainloop`). De esta forma, la aplicación permanece \n",
    "corriendo hasta que el usuario la cierre.\n",
    "\"\"\"\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    app=App()\n",
    "    app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
